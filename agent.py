# agent.py
import os
import json
from openai import OpenAI

from tools import (
    df, dataset_info, tools, available_functions,
    get_data_summary, analyze_distribution, analyze_correlation,
    detect_outliers, compare_groups, analyze_temporal_patterns,
    execute_custom_code
)

# Mem√≥ria do agente
class AgentMemory:
    def __init__(self):
        self.conversation_history = []
        self.analysis_results = {}
        self.conclusions = []
        self.dataset_context = {}

    def add_message(self, role, content):
        self.conversation_history.append({"role": role, "content": content})

    def add_analysis(self, analysis_type, result):
        self.analysis_results[analysis_type] = result

    def add_conclusion(self, conclusion):
        if conclusion not in self.conclusions:
            self.conclusions.append(conclusion)

    def set_dataset_context(self, context):
        self.dataset_context = context

    def get_context(self):
        context = ""
        if self.dataset_context:
            context += "Informa√ß√µes do Dataset:\n"
            context += f"- Arquivo: {self.dataset_context.get('filename', 'N/A')}\n"
            context += f"- Dimens√µes: {self.dataset_context.get('shape', 'N/A')}\n"
            context += f"- Colunas: {', '.join(self.dataset_context.get('columns', []))}\n\n"
        if self.analysis_results:
            context += "An√°lises realizadas:\n"
            for analysis_type in list(self.analysis_results.keys())[-5:]:
                context += f"- {analysis_type}\n"
        if self.conclusions:
            context += "\nConclus√µes anteriores:\n"
            for i, conclusion in enumerate(self.conclusions, 1):
                context += f"{i}. {conclusion}\n"
        return context

    def get_full_history(self):
        return self.conversation_history[-10:]

    def get_initial_history(self):
        return self.conversation_history

    def reset(self):
        self.conversation_history = []
        self.analysis_results = {}
        self.conclusions = []

memory = AgentMemory()

def identify_best_column_for_auto_plot():
    global df, dataset_info
    if df is None or df.empty:
        return None, None
    numeric_cols = dataset_info.get('numeric_columns', [])
    categorical_cols = dataset_info.get('categorical_cols', [])
    if numeric_cols:
        try:
            std_devs = df[numeric_cols].std().sort_values(ascending=False)
            if not std_devs.empty:
                best_col = std_devs.index[0]
                return best_col, "num√©rica com maior vari√¢ncia"
        except:
            pass
    if categorical_cols:
        for col in categorical_cols:
            n_unique = df[col].nunique()
            if 2 <= n_unique <= 10:
                return col, "categ√≥rica ideal para distribui√ß√£o"
        if categorical_cols:
            return categorical_cols[0], "primeira coluna categ√≥rica"
    if dataset_info.get('columns'):
        if numeric_cols:
            return numeric_cols[0], "primeira coluna num√©rica"
        else:
            return dataset_info['columns'][0], "primeira coluna dispon√≠vel"
    return None, None

def run_agent_core(user_query, history=None):
    from tools import df, dataset_info, tools, available_functions  # garantir estado atualizado
    if df is None:
        return "‚ö†Ô∏è Nenhum dataset carregado. Por favor, carregue um arquivo CSV primeiro."
    memory.set_dataset_context(dataset_info)
    system_message = f"""Voc√™ √© um agente especializado em An√°lise Explorat√≥ria de Dados (EDA) gen√©rico e adapt√°vel, focado em fornecer insights detalhados e conclus√µes.

Dataset atual:
- Arquivo: {dataset_info.get('filename', 'desconhecido')}
- Dimens√µes: {df.shape[0]} linhas √ó {df.shape[1]} colunas
- Colunas num√©ricas ({len(dataset_info.get('numeric_columns', []))}): {', '.join(dataset_info.get('numeric_columns', [])[:10])}{'...' if len(dataset_info.get('numeric_columns', [])) > 10 else ''}
- Colunas categ√≥ricas ({len(dataset_info.get('categorical_columns', []))}): {', '.join(dataset_info.get('categorical_columns', [])[:10])}{'...' if len(dataset_info.get('categorical_columns', [])) > 10 else ''}

Voc√™ tem acesso a ferramentas de an√°lise (get_data_summary, analyze_distribution, analyze_correlation, etc.).

Contexto das an√°lises anteriores:
{memory.get_context()}

IMPORTANTE:
- Para a an√°lise inicial ou se for solicitado um resumo, use get_data_summary() primeiro.
- Use as tools de forma sequencial e l√≥gica.
- Adapte suas an√°lises ao tipo de dados.
- Sintetize as informa√ß√µes em conclus√µes acion√°veis.
- Seja proativo em sugerir an√°lises relevantes.
- Responda em portugu√™s de forma clara e estruturada com markdown.
"""
    if history is not None:
        memory.add_message("user", user_query)
        messages = [{"role": "system", "content": system_message}] + memory.get_full_history()
    else:
        messages = [{"role": "system", "content": system_message},
                    {"role": "user", "content": user_query}]
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    max_iterations = 10
    iteration = 0
    final_response_content = None
    while iteration < max_iterations:
        iteration += 1
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
        response_message = response.choices[0].message
        if not getattr(response_message, "tool_calls", None):
            final_response_content = response_message.content
            if final_response_content and any(k in final_response_content.lower() for k in ["conclus√µes", "insights", "resumo dos achados"]):
                memory.add_conclusion(final_response_content)
            memory.add_message("assistant", final_response_content)
            if history is not None:
                history.append([messages[-1]["content"] if messages else "", final_response_content])
                return history
            return final_response_content
        messages.append(response_message)
        for tool_call in response_message.tool_calls:
            function_name = tool_call.function.name
            function_args = json.loads(tool_call.function.arguments) if tool_call.function.arguments else {}
            function_to_call = available_functions[function_name]
            function_response = function_to_call(**function_args)
            memory.add_analysis(function_name, function_args)
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "name": function_name,
                "content": function_response
            })
    error_message = "‚ö†Ô∏è N√∫mero m√°ximo de itera√ß√µes atingido"
    if history is not None:
        history.append([messages[-1]["content"] if messages else "", error_message])
        return history
    return error_message

AUTONOMOUS_PROMPT_EXTENDED = """
Realize uma An√°lise Explorat√≥ria de Dados (EDA) completa e detalhada deste dataset...
## 1. Descri√ß√£o e Estrutura dos Dados (Obrigat√≥rio)
1. Resumo Inicial: Use a tool get_data_summary()
2. Identifica√ß√£o de Tipos
3. Valores Faltantes
4. Duplicatas
## 2. An√°lise Univariada e Distribui√ß√£o (Inclui Gr√°fico Autom√°tico)
5. Distribui√ß√£o Gr√°fica: GERE IMEDIATAMENTE UM GR√ÅFICO com analyze_distribution
6-8. Medidas de tend√™ncia e variabilidade; frequ√™ncias categ√≥ricas
## 3. Detec√ß√£o de Anomalias (Outliers)
9-10. detect_outliers em pelo menos duas colunas e recomenda√ß√µes
## 4. Rela√ß√µes e Padr√µes (Multivariada)
11-14. analyze_correlation (gr√°fico), top correla√ß√µes, compare_groups
## 5. An√°lises Adicionais
15-24. Temporal (se aplic√°vel), homogeneidade, features, balanceamento, cardinalidade, bi-variadas, quartis, skew/kurtosis, pr√≥ximos passos, clusters
## 6. Conclus√µes Finais
25. S√≠ntese dos achados.
"""

def autonomous_analysis():
    from tools import df  # estado atualizado
    if df is None:
        return [], "‚ùå Nenhum dataset carregado para an√°lise aut√¥noma."
    memory.reset()
    col_to_plot, reason = identify_best_column_for_auto_plot()
    if not col_to_plot:
        initial_response = "‚ùå Erro: N√£o foi poss√≠vel identificar colunas para an√°lise."
        return [], initial_response
    initial_analysis_prompt = f"""
{AUTONOMOUS_PROMPT_EXTENDED}

EXECU√á√ÉO INICIAL FOR√áADA:
- Use get_data_summary() primeiro.
- Em seguida execute analyze_distribution(column='{col_to_plot}').
- Continue com o plano de an√°lise.
"""
    final_response = run_agent_core(initial_analysis_prompt, history=None)
    analysis_history = memory.get_initial_history()
    formatted_history = []
    for item in analysis_history:
        if item["role"] == "assistant":
            if formatted_history and formatted_history[-1][1] is None:
                formatted_history[-1][1] = item["content"]
            else:
                formatted_history.append(["**An√°lise Aut√¥noma**", item["content"]])
    if formatted_history and formatted_history[-1][1] is not None:
        formatted_history.append([None, "üëã **An√°lise Aut√¥noma Conclu√≠da!**\n\nAgora, sinta-se √† vontade para fazer perguntas detalhadas sobre os dados."])
    return formatted_history, final_response
