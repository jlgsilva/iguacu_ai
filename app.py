import gradio as gr
import os
import zipfile
import py7zr
import tempfile
import xml.etree.ElementTree as ET
import json
from pathlib import Path
import time
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from google import genai
from google.genai import types

# ===========================================================
# CONFIGURAÃ‡ÃƒO DO CLIENTE GEMINI
# ===========================================================
client = None
try:
    client = genai.Client()
    print("Cliente Gemini inicializado com sucesso.")
except Exception as e:
    print(f"Erro ao inicializar cliente Gemini: {e}")
    print("Verifique se a variÃ¡vel de ambiente GEMINI_API_KEY estÃ¡ configurada corretamente.")

# ===========================================================
# ESTADO GLOBAL
# ===========================================================
class AppState:
    def __init__(self):
        self.df = None
        self.analysis_results = {}
        self.csv_path = None
        self.summary_stats = None
        self.plots = {}

state = AppState()

# ===========================================================
# FUNÃ‡Ã•ES AUXILIARES DE PARSE E EXTRAÃ‡ÃƒO
# ===========================================================
def parse_nfe(xml_path):
    ns = {"nfe": "http://www.portalfiscal.inf.br/nfe"}
    tree = ET.parse(xml_path)
    root = tree.getroot()
    infNFe = root.find(".//nfe:infNFe", ns)
    if infNFe is None:
        raise ValueError("Estrutura de NF-e invÃ¡lida")

    def gettext_local(tag, parent):
        elem = parent.find(f"nfe:{tag}", ns)
        return elem.text.strip() if elem is not None and elem.text else None

    ide = infNFe.find("nfe:ide", ns)
    emit = infNFe.find("nfe:emit", ns)
    dest = infNFe.find("nfe:dest", ns)
    total = infNFe.find(".//nfe:total/nfe:ICMSTot", ns)

    nfe_data = {
        "chave": infNFe.attrib.get("Id", ""),
        "numero": gettext_local("nNF", ide),
        "data_emissao": gettext_local("dhEmi", ide),
        "natureza_operacao": gettext_local("natOp", ide),
        "modelo": gettext_local("mod", ide),
        "serie": gettext_local("serie", ide),
        "tipo_operacao": gettext_local("tpNF", ide),
    }

    if emit is not None:
        nfe_data["emitente_cnpj"] = gettext_local("CNPJ", emit)
        nfe_data["emitente_nome"] = gettext_local("xNome", emit)

    if dest is not None:
        nfe_data["destinatario_cnpj"] = gettext_local("CNPJ", dest)
        nfe_data["destinatario_nome"] = gettext_local("xNome", dest)

    if total is not None:
        nfe_data["valor_nf"] = gettext_local("vNF", total)

    itens = []
    for det in infNFe.findall("nfe:det", ns):
        prod = det.find("nfe:prod", ns)
        if prod is not None:
            item = {
                "item": det.attrib.get("nItem"),
                "codigo": gettext_local("cProd", prod),
                "descricao": gettext_local("xProd", prod),
                "ncm": gettext_local("NCM", prod),
                "cfop": gettext_local("CFOP", prod),
                "unidade": gettext_local("uCom", prod),
                "quantidade": gettext_local("qCom", prod),
                "valor_unitario": gettext_local("vUnCom", prod),
                "valor_total": gettext_local("vProd", prod),
            }
            itens.append(item)
    
    nfe_data["itens"] = json.dumps(itens, ensure_ascii=False)
    return nfe_data

def extract_archive(file_path, extract_to):
    if file_path.endswith(".zip"):
        with zipfile.ZipFile(file_path, "r") as zip_ref:
            zip_ref.extractall(extract_to)
    elif file_path.endswith(".7z"):
        with py7zr.SevenZipFile(file_path, "r") as archive:
            archive.extractall(extract_to)
    else:
        raise ValueError("Formato de arquivo nÃ£o suportado. Use .zip ou .7z")

# ===========================================================
# ANÃLISE COM GEMINI E GERAÃ‡ÃƒO DE GRÃFICOS
# ===========================================================
def generate_monthly_spending_chart(df):
    """Gera histograma de gastos mensais"""
    try:
        df_copy = df.copy()
        
        # Usar coluna jÃ¡ processada
        if 'mes_ano' not in df_copy.columns:
            print("âœ— Coluna 'mes_ano' nÃ£o encontrada")
            return None
            
        monthly = df_copy.groupby('mes_ano')['valor_nf'].sum().reset_index()
        monthly = monthly.sort_values('mes_ano')
        
        if len(monthly) == 0:
            print("âœ— Nenhum dado mensal para plotar")
            return None
        
        fig, ax = plt.subplots(figsize=(14, 7))
        bars = ax.bar(monthly['mes_ano'], monthly['valor_nf'], color='steelblue', 
                      edgecolor='black', linewidth=1.5)
        
        # Adicionar valores no topo das barras
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'R$ {height:,.0f}',
                   ha='center', va='bottom', fontsize=9, fontweight='bold')
        
        ax.set_xlabel('MÃªs/Ano', fontsize=13, fontweight='bold')
        ax.set_ylabel('Valor Total (R$)', fontsize=13, fontweight='bold')
        ax.set_title('Gastos Mensais - Notas Fiscais', fontsize=16, fontweight='bold', pad=20)
        ax.tick_params(axis='x', rotation=45)
        ax.grid(axis='y', alpha=0.3, linestyle='--')
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
        plt.tight_layout()
        
        path = os.path.join(tempfile.gettempdir(), "monthly_spending.png")
        plt.savefig(path, dpi=150, bbox_inches="tight")
        plt.close(fig)
        
        print(f"âœ“ GrÃ¡fico mensal gerado: {len(monthly)} meses plotados")
        return path
    except Exception as e:
        print(f"âœ— Erro ao gerar grÃ¡fico mensal: {e}")
        import traceback
        traceback.print_exc()
        return None

def generate_top_items_chart(df):
    """Gera grÃ¡fico dos top 10 itens mais comprados"""
    try:
        all_items = []
        for itens_str in df['itens'].dropna():
            try:
                itens = json.loads(itens_str)
                for item in itens:
                    desc = item.get('descricao', '').upper().strip()
                    valor = float(item.get('valor_total', 0))
                    if desc and valor > 0:
                        all_items.append({'descricao': desc, 'valor': valor})
            except:
                continue
        
        if not all_items:
            print("âœ— Nenhum item vÃ¡lido encontrado")
            return None
            
        items_df = pd.DataFrame(all_items)
        top_items = items_df.groupby('descricao')['valor'].sum().nlargest(10).reset_index()
        
        # Truncar nomes longos
        top_items['descricao_curta'] = top_items['descricao'].apply(
            lambda x: x[:60] + '...' if len(x) > 60 else x
        )
        
        fig, ax = plt.subplots(figsize=(14, 8))
        bars = ax.barh(top_items['descricao_curta'], top_items['valor'], 
                       color='coral', edgecolor='black', linewidth=1.5)
        
        # Adicionar valores
        for i, (bar, val) in enumerate(zip(bars, top_items['valor'])):
            ax.text(val, bar.get_y() + bar.get_height()/2, 
                   f'R$ {val:,.2f}',
                   ha='left', va='center', fontsize=9, fontweight='bold', 
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
        
        ax.set_xlabel('Valor Total (R$)', fontsize=13, fontweight='bold')
        ax.set_ylabel('Item', fontsize=13, fontweight='bold')
        ax.set_title('Top 10 Itens Mais Comprados (por valor)', fontsize=16, fontweight='bold', pad=20)
        ax.invert_yaxis()
        ax.grid(axis='x', alpha=0.3, linestyle='--')
        plt.tight_layout()
        
        path = os.path.join(tempfile.gettempdir(), "top_items.png")
        plt.savefig(path, dpi=150, bbox_inches="tight")
        plt.close(fig)
        
        print(f"âœ“ GrÃ¡fico Top 10 gerado: {path}")
        return path
    except Exception as e:
        print(f"âœ— Erro ao gerar grÃ¡fico de itens: {e}")
        import traceback
        traceback.print_exc()
        return None

def estimate_co2_emissions(df):
    """Estima emissÃµes de CO2 baseado em categorias de produtos"""
    try:
        # Fatores mÃ©dios de emissÃ£o por categoria (kg CO2 / R$)
        emission_factors = {
            'alimentos': 0.5,
            'eletrÃ´nicos': 1.2,
            'construÃ§Ã£o': 0.8,
            'limpeza': 0.3,
            'vestuÃ¡rio': 0.6,
            'mÃ³veis': 0.7,
            'outros': 0.5
        }
        
        def categorize_item(desc):
            desc_lower = desc.lower()
            if any(word in desc_lower for word in ['aliment', 'comida', 'cafe', 'arroz', 'feijao', 'massa', 'leite', 'oleo', 'acucar']):
                return 'alimentos'
            elif any(word in desc_lower for word in ['eletro', 'cabo', 'lamp', 'camera', 'monitor', 'tomada', 'condutor']):
                return 'eletrÃ´nicos'
            elif any(word in desc_lower for word in ['cimento', 'massa corrida', 'tinta', 'areia', 'cano', 'tubo', 'registro']):
                return 'construÃ§Ã£o'
            elif any(word in desc_lower for word in ['limpeza', 'detergente', 'sabao', 'desinfetante', 'alcool', 'hipoclorito']):
                return 'limpeza'
            elif any(word in desc_lower for word in ['camiseta', 'calca', 'uniforme', 'jaleco', 'bota', 'luva']):
                return 'vestuÃ¡rio'
            elif any(word in desc_lower for word in ['movel', 'cadeira', 'mesa']):
                return 'mÃ³veis'
            return 'outros'
        
        df_copy = df.copy()
        
        # Usar coluna jÃ¡ processada
        if 'mes_ano' not in df_copy.columns:
            print("âœ— Coluna 'mes_ano' nÃ£o encontrada para CO2")
            return None, {}
        
        monthly_co2 = []
        monthly_details = {}
        
        for mes in sorted(df_copy['mes_ano'].dropna().unique()):
            mes_data = df_copy[df_copy['mes_ano'] == mes]
            total_co2 = 0
            categoria_co2 = {}
            
            for itens_str in mes_data['itens'].dropna():
                try:
                    itens = json.loads(itens_str)
                    for item in itens:
                        desc = item.get('descricao', '')
                        valor = float(item.get('valor_total', 0))
                        if valor > 0:
                            categoria = categorize_item(desc)
                            co2 = valor * emission_factors[categoria]
                            total_co2 += co2
                            categoria_co2[categoria] = categoria_co2.get(categoria, 0) + co2
                except:
                    continue
            
            mes_str = str(mes)
            monthly_co2.append({'mes_ano': mes_str, 'co2_kg': total_co2})
            monthly_details[mes_str] = categoria_co2
        
        if not monthly_co2:
            print("âœ— Nenhum dado de CO2 calculado")
            return None, {}
            
        co2_df = pd.DataFrame(monthly_co2).sort_values('mes_ano')
        
        fig, ax = plt.subplots(figsize=(14, 7))
        
        # Linha principal
        line = ax.plot(co2_df['mes_ano'], co2_df['co2_kg'], 
                      marker='o', linewidth=3, color='darkgreen', 
                      markersize=10, markeredgecolor='black', markeredgewidth=1.5,
                      label='EmissÃµes Totais')[0]
        
        # Ãrea preenchida
        ax.fill_between(range(len(co2_df)), co2_df['co2_kg'], 
                       alpha=0.3, color='lightgreen')
        
        # Valores nos pontos
        for i, (x, y) in enumerate(zip(co2_df['mes_ano'], co2_df['co2_kg'])):
            ax.text(i, y, f'{y:.1f} kg', 
                   ha='center', va='bottom', fontsize=9, fontweight='bold',
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
        
        ax.set_xlabel('MÃªs/Ano', fontsize=13, fontweight='bold')
        ax.set_ylabel('EmissÃµes de COâ‚‚ (kg)', fontsize=13, fontweight='bold')
        ax.set_title('Estimativa de EmissÃµes de COâ‚‚ Mensais', fontsize=16, fontweight='bold', pad=20)
        ax.tick_params(axis='x', rotation=45)
        ax.grid(alpha=0.3, linestyle='--')
        ax.legend(loc='upper left', fontsize=11)
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
        plt.tight_layout()
        
        path = os.path.join(tempfile.gettempdir(), "co2_emissions.png")
        plt.savefig(path, dpi=150, bbox_inches="tight")
        plt.close(fig)
        
        # Calcular totais
        total_co2 = co2_df['co2_kg'].sum()
        co2_summary = {
            'total_kg': total_co2,
            'total_ton': total_co2 / 1000,
            'monthly_data': co2_df.to_dict('records'),
            'category_details': monthly_details,
            'emission_factors': emission_factors
        }
        
        print(f"âœ“ GrÃ¡fico CO2 gerado: {len(co2_df)} meses")
        print(f"  Total CO2: {total_co2:.2f} kg ({total_co2/1000:.3f} ton)")
        
        return path, co2_summary
    except Exception as e:
        print(f"âœ— Erro ao estimar CO2: {e}")
        import traceback
        traceback.print_exc()
        return None, {}

def call_gemini_analysis(prompt, data_summary):
    """Chama API Gemini para anÃ¡lise"""
    if client is None:
        return "Erro: Cliente Gemini nÃ£o inicializado."
    
    full_prompt = f"""VocÃª Ã© um analista de dados especializado em Notas Fiscais eletrÃ´nicas brasileiras (NF-e).

CONTEXTO DOS DADOS:
{data_summary}

TAREFA:
{prompt}

ForneÃ§a uma anÃ¡lise detalhada, profissional e objetiva."""

    try:
        response = client.models.generate_content(
            model="gemini-2.0-flash-exp",
            contents=full_prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                max_output_tokens=4000
            )
        )
        return response.text
    except Exception as e:
        return f"Erro ao chamar API Gemini: {str(e)}"

def analyze_data_structure_with_gemini(df):
    """Usa Gemini para analisar estrutura dos dados e sugerir melhor forma de processar datas"""
    try:
        sample_dates = df['data_emissao'].head(10).tolist()
        sample_data = df.head(5).to_dict('records')
        
        structure_prompt = f"""Analise a estrutura deste dataset de Notas Fiscais e responda OBJETIVAMENTE:

AMOSTRA DE DATAS:
{sample_dates}

AMOSTRA DE REGISTROS:
{json.dumps(sample_data, indent=2, ensure_ascii=False)[:1000]}

PERGUNTAS:
1. Qual o formato exato das datas? (ex: ISO 8601 com timezone)
2. Como extrair mÃªs e ano dessas datas em Python/Pandas?
3. HÃ¡ datas invÃ¡lidas ou nulas que precisam ser tratadas?
4. Qual a melhor estratÃ©gia para agrupar por mÃªs/ano?

Seja TÃ‰CNICO e DIRETO. Responda em formato de cÃ³digo Python quando aplicÃ¡vel."""

        response = call_gemini_analysis(structure_prompt, "")
        print("\nğŸ¤– AnÃ¡lise Gemini da estrutura:")
        print(response[:500])
        
        return response
    except Exception as e:
        print(f"Erro na anÃ¡lise de estrutura: {e}")
        return None

def perform_autonomous_analysis(df):
    """Executa anÃ¡lise autÃ´noma completa"""
    try:
        print("\n" + "="*60)
        print("INICIANDO ANÃLISE AUTÃ”NOMA")
        print("="*60)
        
        # ANÃLISE PRÃ‰VIA COM GEMINI
        print("\nğŸ” Analisando estrutura dos dados com Gemini...")
        analyze_data_structure_with_gemini(df)
        
        # Criar cÃ³pia para nÃ£o modificar o original
        df_work = df.copy()
        
        # Preparar estatÃ­sticas detalhadas
        total_nfs = len(df_work)
        df_work['valor_nf'] = pd.to_numeric(df_work['valor_nf'], errors='coerce')
        total_valor = df_work['valor_nf'].sum()
        
        print("\nğŸ“… Processando datas...")
        print(f"Amostra de datas originais: {df_work['data_emissao'].head(3).tolist()}")
        
        # CONVERSÃƒO ROBUSTA DE DATAS COM MÃšLTIPLAS TENTATIVAS
        # Formato: 2021-09-14T08:26:00-03:00 (ISO 8601 com timezone)
        df_work['data_emissao_original'] = df_work['data_emissao']
        
        # Tentativa 1: ConversÃ£o direta
        df_work['data_emissao_dt'] = pd.to_datetime(df_work['data_emissao'], errors='coerce', utc=True)
        
        # Tentativa 2: Remover timezone manualmente se necessÃ¡rio
        if df_work['data_emissao_dt'].isna().all():
            print("âš ï¸ ConversÃ£o direta falhou, tentando remover timezone...")
            df_work['data_emissao_clean'] = df_work['data_emissao'].astype(str).str.slice(0, 19)
            df_work['data_emissao_dt'] = pd.to_datetime(df_work['data_emissao_clean'], errors='coerce')
        
        # Filtrar apenas registros com datas vÃ¡lidas
        df_com_data = df_work[df_work['data_emissao_dt'].notna()].copy()
        
        print(f"âœ“ Datas convertidas: {len(df_com_data)} de {len(df_work)} registros")
        print(f"Amostra convertida: {df_com_data['data_emissao_dt'].head(3).tolist()}")
        
        if len(df_com_data) == 0:
            error_msg = """âŒ Erro: Nenhuma data vÃ¡lida encontrada no dataset.

DIAGNÃ“STICO:
1. Formato detectado das datas nÃ£o Ã© compatÃ­vel com pandas
2. Verifique se a coluna 'data_emissao' existe e contÃ©m valores vÃ¡lidos
3. Formato esperado: ISO 8601 (ex: 2021-09-14T08:26:00-03:00)

SOLUÃ‡ÃƒO:
- Revise o processo de extraÃ§Ã£o dos XMLs
- Garanta que as datas sejam extraÃ­das corretamente"""
            return error_msg, [None, None, None]
        
        data_inicio = df_com_data['data_emissao_dt'].min()
        data_fim = df_com_data['data_emissao_dt'].max()
        
        # Extrair mÃªs/ano
        df_com_data['ano'] = df_com_data['data_emissao_dt'].dt.year
        df_com_data['mes'] = df_com_data['data_emissao_dt'].dt.month
        df_com_data['mes_ano_str'] = df_com_data['data_emissao_dt'].dt.strftime('%Y-%m')
        
        print(f"âœ“ ExtraÃ­do ano/mÃªs: {df_com_data['mes_ano_str'].head(3).tolist()}")
        
        # EstatÃ­sticas mensais
        monthly_stats = df_com_data.groupby('mes_ano_str').agg({
            'valor_nf': ['sum', 'count', 'mean']
        }).reset_index()
        
        monthly_stats.columns = ['MÃªs/Ano', 'Total (R$)', 'Qtd NFs', 'MÃ©dia (R$)']
        monthly_stats = monthly_stats.sort_values('MÃªs/Ano')
        
        # Formatar valores para exibiÃ§Ã£o
        monthly_display = monthly_stats.copy()
        monthly_display['Total (R$)'] = monthly_display['Total (R$)'].apply(lambda x: f'R$ {x:,.2f}')
        monthly_display['MÃ©dia (R$)'] = monthly_display['MÃ©dia (R$)'].apply(lambda x: f'R$ {x:,.2f}')
        
        fornecedores = df_work['emitente_nome'].nunique()
        top_fornecedores = df_com_data.groupby('emitente_nome')['valor_nf'].sum().nlargest(5)
        
        # AnÃ¡lise de itens
        total_itens = 0
        for itens_str in df_work['itens'].dropna():
            try:
                itens = json.loads(itens_str)
                total_itens += len(itens)
            except:
                continue
        
        data_summary = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESUMO EXECUTIVO DO DATASET - NOTAS FISCAIS ELETRÃ”NICAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š INFORMAÃ‡Ã•ES GERAIS:
  â€¢ Total de Notas Fiscais: {total_nfs}
  â€¢ Valor Total Acumulado: R$ {total_valor:,.2f}
  â€¢ PerÃ­odo Analisado: {data_inicio.strftime('%d/%m/%Y')} a {data_fim.strftime('%d/%m/%Y')}
  â€¢ NÃºmero de Fornecedores Distintos: {fornecedores}
  â€¢ Total de Itens Comprados: {total_itens}

ğŸ“… DISTRIBUIÃ‡ÃƒO TEMPORAL:
  Formato Original: ISO 8601 com timezone (ex: 2021-09-14T08:26:00-03:00)
  Colunas extraÃ­das: ano, mÃªs, mes_ano_str
  
  DistribuiÃ§Ã£o Mensal de Gastos:
{monthly_display.to_string(index=False)}

ğŸ’° TOP 5 FORNECEDORES (por valor):
{chr(10).join([f"  â€¢ {nome}: R$ {valor:,.2f}" for nome, valor in top_fornecedores.items()])}

ğŸ” ESTRUTURA DOS DADOS:
  Colunas disponÃ­veis: {', '.join(df_work.columns)}
  
  A coluna 'itens' contÃ©m JSON com detalhes de cada produto:
  - descricao: nome do produto
  - valor_total: valor do item
  - quantidade: quantidade comprada
  - ncm: cÃ³digo NCM (classificaÃ§Ã£o fiscal)
  - cfop: cÃ³digo de operaÃ§Ã£o fiscal
"""

        print("âœ“ Resumo preparado")
        
        # Gerar grÃ¡ficos com o DataFrame processado
        print("\nğŸ“Š Gerando visualizaÃ§Ãµes...")
        
        # Preparar dados para grÃ¡ficos
        df_plot = df_com_data.copy()
        df_plot['mes_ano'] = df_plot['mes_ano_str']  # Usar string para compatibilidade
        
        plot1 = generate_monthly_spending_chart(df_plot)
        plot2 = generate_top_items_chart(df_work)
        plot3, co2_summary = estimate_co2_emissions(df_plot)
        
        # Preparar resumo de CO2
        co2_text = ""
        if co2_summary:
            co2_text = f"""

ğŸŒ± RESUMO DE EMISSÃ•ES DE COâ‚‚:
  â€¢ Total Estimado: {co2_summary['total_kg']:.2f} kg ({co2_summary['total_ton']:.4f} toneladas)
  â€¢ PerÃ­odo: {data_inicio.strftime('%m/%Y')} a {data_fim.strftime('%m/%Y')}
  
  DistribuiÃ§Ã£o Mensal:
{chr(10).join([f"    - {item['mes_ano']}: {item['co2_kg']:.2f} kg COâ‚‚" for item in co2_summary['monthly_data']])}

  Fatores de EmissÃ£o Utilizados (kg COâ‚‚ por R$ gasto):
{chr(10).join([f"    â€¢ {cat.capitalize()}: {fator}" for cat, fator in co2_summary['emission_factors'].items()])}
"""
        
        # AnÃ¡lise com Gemini
        print("\nğŸ¤– Consultando Gemini 2.5 Flash para anÃ¡lise completa...")
        
        analysis_prompt = f"""Com base nos dados fornecidos, realize uma anÃ¡lise COMPLETA e DETALHADA respondendo:

1. **ANÃLISE TEMPORAL E SAZONALIDADE:**
   - Analise a distribuiÃ§Ã£o mensal de gastos apresentada na tabela
   - Identifique padrÃµes, tendÃªncias de crescimento ou reduÃ§Ã£o
   - HÃ¡ concentraÃ§Ã£o de gastos em perÃ­odos especÃ­ficos? 
   - Qual foi o mÃªs de maior e menor gasto?
   - Calcule a variaÃ§Ã£o percentual entre os meses

2. **FORNECEDORES E CATEGORIAS:**
   - Analise o Top 5 de fornecedores apresentado
   - Qual a concentraÃ§Ã£o de gastos? (ex: top 3 representa X% do total)
   - Com base nos nomes dos fornecedores, qual o perfil de compras?
   - HÃ¡ dependÃªncia excessiva de poucos fornecedores?

3. **ANOMALIAS E ATENÃ‡ÃƒO:**
   - Com {total_nfs} notas fiscais em {len(monthly_stats)} meses, identifique perÃ­odos atÃ­picos
   - HÃ¡ meses sem notas fiscais? Se sim, quais e por quÃª isso pode ser relevante?
   - O valor mÃ©dio por nota fiscal estÃ¡ consistente ou hÃ¡ variaÃ§Ãµes grandes?

4. **OTIMIZAÃ‡ÃƒO E RECOMENDAÃ‡Ã•ES:**
   - Quais aÃ§Ãµes prÃ¡ticas e especÃ­ficas podem reduzir custos?
   - Onde focar negociaÃ§Ãµes com fornecedores?
   - HÃ¡ oportunidades de consolidaÃ§Ã£o de compras?

5. **PERFIL ORGANIZACIONAL:**
   - Com base nos fornecedores e valores, qual o tipo de organizaÃ§Ã£o? (indÃºstria, comÃ©rcio, serviÃ§os, etc)
   - Quais as principais necessidades de compra identificadas?

6. **ANÃLISE DE SUSTENTABILIDADE (COâ‚‚):**
{co2_text}
   
   Com base nas emissÃµes estimadas:
   - Qual a tendÃªncia das emissÃµes ao longo dos meses?
   - Quais categorias de produtos contribuem mais para as emissÃµes?
   - Que aÃ§Ãµes poderiam reduzir a pegada de carbono sem comprometer operaÃ§Ãµes?
   - Compare as emissÃµes com benchmarks do setor pÃºblico brasileiro (se conhecer)

IMPORTANTE: Use os nÃºmeros especÃ­ficos fornecidos. Seja OBJETIVO e DIRETO nas respostas."""

        analysis_text = call_gemini_analysis(analysis_prompt, data_summary)
        
        print("âœ“ AnÃ¡lise Gemini concluÃ­da")
        
        # Metodologia CO2
        methodology = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
METODOLOGIA DE ESTIMATIVA DE EMISSÃ•ES DE COâ‚‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š REFERÃŠNCIAS UTILIZADAS:
  1. DEFRA 2023 - Department for Environment, Food & Rural Affairs (Reino Unido)
     Conversion factors for greenhouse gas reporting
     
  2. IPCC AR6 - Intergovernmental Panel on Climate Change
     Sixth Assessment Report - Working Group III (2022)
     Global Warming Potential (GWP-100)

ğŸ”¬ FATORES DE EMISSÃƒO APLICADOS (kg COâ‚‚eq / R$ gasto):

  Categoria         | Fator | Base
  ------------------|-------|------------------------------------------
  Alimentos         | 0.5   | MÃ©dia para produtos alimentÃ­cios gerais
  EletrÃ´nicos       | 1.2   | FabricaÃ§Ã£o e transporte de eletrÃ´nicos
  ConstruÃ§Ã£o        | 0.8   | Cimento, aÃ§o, materiais de construÃ§Ã£o
  Limpeza           | 0.3   | Produtos quÃ­micos de limpeza
  VestuÃ¡rio         | 0.6   | TÃªxteis e confecÃ§Ãµes
  MÃ³veis            | 0.7   | Madeira e metais processados
  Outros            | 0.5   | MÃ©dia genÃ©rica

ğŸ” PROCESSO DE CATEGORIZAÃ‡ÃƒO:
  Os produtos foram classificados automaticamente atravÃ©s de anÃ¡lise de 
  palavras-chave nas descriÃ§Ãµes dos itens das notas fiscais.
  
  Exemplos de palavras-chave:
  â€¢ Alimentos: cafÃ©, arroz, feijÃ£o, massa, leite, Ã³leo, aÃ§Ãºcar
  â€¢ EletrÃ´nicos: cabo, lÃ¢mpada, cÃ¢mera, monitor, tomada
  â€¢ ConstruÃ§Ã£o: cimento, tinta, areia, cano, tubo, registro
  â€¢ Limpeza: detergente, sabÃ£o, desinfetante, Ã¡lcool, hipoclorito

âš ï¸ LIMITAÃ‡Ã•ES E DISCLAIMERS:
  1. Valores aproximados para anÃ¡lise comparativa e gestÃ£o interna
  2. NÃƒO devem ser usados para:
     - InventÃ¡rios oficiais de GEE (Gases de Efeito Estufa)
     - RelatÃ³rios de sustentabilidade certificados
     - CompensaÃ§Ã£o de carbono oficial
  3. Para relatÃ³rios oficiais, recomenda-se:
     - AnÃ¡lise especÃ­fica por produto com dados do fabricante
     - Uso de ferramentas certificadas (GHG Protocol, ISO 14064)
     - ValidaÃ§Ã£o por terceiros credenciados

ğŸ“Š PRECISÃƒO ESTIMADA:
  â€¢ Margem de erro: Â±30% (devido Ã  categorizaÃ§Ã£o genÃ©rica)
  â€¢ Adequado para: identificaÃ§Ã£o de tendÃªncias e hotspots
  â€¢ RecomendaÃ§Ã£o: usar para decisÃµes estratÃ©gicas, nÃ£o para compliance

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        full_analysis = f"""# ğŸ“Š ANÃLISE AUTOMÃTICA - NOTAS FISCAIS ELETRÃ”NICAS
### Powered by Gemini 2.5 Flash

{data_summary}

## ğŸ” ANÃLISE DETALHADA DA IA

{analysis_text}

{methodology}

---
**ğŸ’¡ Dica:** VocÃª pode fazer perguntas adicionais no chat interativo abaixo sobre qualquer aspecto desta anÃ¡lise.
"""
        
        state.analysis_results = {
            'full_analysis': full_analysis,
            'plots': [plot1, plot2, plot3],
            'co2_summary': co2_summary
        }
        
        # Atualizar o estado global com o DataFrame processado
        state.df = df_com_data
        
        print("\nâœ“âœ“âœ“ ANÃLISE COMPLETA FINALIZADA âœ“âœ“âœ“\n")
        
        return full_analysis, [plot1, plot2, plot3]
        
    except Exception as e:
        error_msg = f"âŒ Erro na anÃ¡lise autÃ´noma: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return error_msg, [None, None, None]

# ===========================================================
# PROCESSAMENTO PRINCIPAL
# ===========================================================
def process_archive(uploaded_file):
    start_time = time.time()
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Extrair arquivo
        file_path = uploaded_file.name if hasattr(uploaded_file, 'name') else uploaded_file
        extract_archive(file_path, temp_dir)
        
        # Encontrar XMLs
        xml_files = list(Path(temp_dir).rglob("*.xml"))
        
        if not xml_files:
            yield "âŒ Nenhum arquivo XML encontrado no arquivo compactado.", None, None, None, None, None, gr.update(interactive=False)
            return
        
        yield f"ğŸ“¦ Processando {len(xml_files)} arquivos XML...", None, None, None, None, None, gr.update(interactive=False)
        
        # Parse XMLs
        nfe_data = []
        for xml_file in xml_files:
            try:
                data = parse_nfe(xml_file)
                nfe_data.append(data)
            except Exception as e:
                print(f"Erro em {xml_file}: {e}")
                continue
        
        if not nfe_data:
            yield "âŒ NÃ£o foi possÃ­vel processar nenhum XML vÃ¡lido.", None, None, None, None, None, gr.update(interactive=False)
            return
        
        # Criar DataFrame
        df = pd.DataFrame(nfe_data)
        df["valor_nf"] = pd.to_numeric(df["valor_nf"], errors="coerce")
        
        # Salvar CSV
        csv_path = os.path.join(temp_dir, "notas_fiscais.csv")
        df.to_csv(csv_path, sep=";", index=False, encoding="utf-8")
        
        state.df = df
        state.csv_path = csv_path
        
        yield (
            f"âœ… {len(nfe_data)} notas fiscais processadas!\n\nğŸ¤– Iniciando anÃ¡lise com Gemini 2.5 Flash...",
            df.head(20),
            csv_path,
            None, None, None,
            gr.update(interactive=False)
        )
        
        # AnÃ¡lise com Gemini
        analysis_text, plots = perform_autonomous_analysis(df)
        
        elapsed = int(time.time() - start_time)
        final_msg = f"""âœ… ANÃLISE CONCLUÃDA EM {elapsed}s

{analysis_text}

ğŸ’¬ VocÃª pode fazer perguntas adicionais no chat interativo abaixo."""
        
        yield (
            final_msg,
            df.head(20),
            csv_path,
            plots[0], plots[1], plots[2],
            gr.update(interactive=True)
        )
        
    except Exception as e:
        yield f"âŒ Erro: {str(e)}", None, None, None, None, None, gr.update(interactive=False)

# ===========================================================
# CHAT INTERATIVO
# ===========================================================
def chat_response(message, history):
    if state.df is None:
        return history + [(message, "âš ï¸ Por favor, processe um arquivo primeiro.")]
    
    # Preparar contexto
    context = f"""VocÃª tem acesso aos seguintes dados analisados:

ANÃLISE PRÃ‰VIA:
{state.analysis_results.get('full_analysis', 'AnÃ¡lise nÃ£o disponÃ­vel')}

ESTATÃSTICAS DO DATASET:
- Total de registros: {len(state.df)}
- Valor total: R$ {state.df['valor_nf'].sum():,.2f}
- PerÃ­odo: {pd.to_datetime(state.df['data_emissao']).min()} a {pd.to_datetime(state.df['data_emissao']).max()}

PERGUNTA DO USUÃRIO:
{message}

Responda de forma precisa e baseada nos dados."""
    
    response = call_gemini_analysis(message, context)
    return history + [(message, response)]

# ===========================================================
# INTERFACE GRADIO
# ===========================================================
with gr.Blocks(title="Processador NF-e com IA", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ“Š Processador Inteligente de Notas Fiscais (NF-e)
    ### Powered by Gemini 2.5 Flash
    
    Envie um arquivo compactado (.zip ou .7z) com XMLs de NF-e para anÃ¡lise automÃ¡tica com IA.
    """)
    
    with gr.Row():
        arquivo_input = gr.File(
            label="ğŸ“ Arquivo Compactado (.zip ou .7z)",
            file_types=[".zip", ".7z"]
        )
    
    botao = gr.Button("ğŸš€ Processar e Analisar", variant="primary", size="lg")
    
    saida_texto = gr.Markdown("Aguardando arquivo...")
    
    gr.Markdown("## ğŸ“‹ Dados Consolidados")
    tabela_csv = gr.Dataframe(label="Amostra do CSV Unificado", interactive=False)
    csv_download = gr.File(label="â¬‡ï¸ Baixar CSV Completo")
    
    gr.Markdown("## ğŸ“ˆ VisualizaÃ§Ãµes Geradas pela IA")
    
    plot1 = gr.Image(label="ğŸ’° Gastos Mensais")
    plot2 = gr.Image(label="ğŸ›’ Top 10 Itens")
    plot3 = gr.Image(label="ğŸŒ± EmissÃµes de COâ‚‚")
    
    gr.Markdown("## ğŸ’¬ Chat Interativo com IA")
    chatbot = gr.Chatbot(label="Converse sobre os dados", height=400)
    with gr.Row():
        chat_input = gr.Textbox(
            label="Sua pergunta",
            placeholder="Ex: Qual foi o mÃªs de maior gasto?",
            interactive=False
        )
        submit_btn = gr.Button("Enviar", variant="primary")
    clear_btn = gr.Button("ğŸ—‘ï¸ Limpar Chat")
    
    # Eventos
    botao.click(
        fn=process_archive,
        inputs=arquivo_input,
        outputs=[saida_texto, tabela_csv, csv_download, plot1, plot2, plot3, chat_input]
    )
    
    submit_btn.click(
        fn=chat_response,
        inputs=[chat_input, chatbot],
        outputs=[chatbot]
    ).then(
        lambda: "",
        None,
        chat_input
    )
    
    chat_input.submit(
        fn=chat_response,
        inputs=[chat_input, chatbot],
        outputs=[chatbot]
    ).then(
        lambda: "",
        None,
        chat_input
    )
    
    clear_btn.click(lambda: None, None, chatbot)

if __name__ == "__main__":
    demo.launch()
