{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlgsilva/iguacu_ai/blob/main/Agentes_Aut%C3%B4nomos_%E2%80%93_Atividade_Extra\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "import warnings\n",
        "from google.colab import files, userdata\n",
        "import getpass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "from io import StringIO\n",
        "from IPython.display import display, Markdown, HTML, Image\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "jnU1hvTpt3AU"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 1: Instala√ß√£o de Depend√™ncias ---\n",
        "!pip install openai pandas matplotlib seaborn plotly kagglehub gradio -q"
      ],
      "metadata": {
        "id": "BbdrBO1TnWwi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 2: Configura√ß√£o Inicial e Sistema de Upload ---\n",
        "\n",
        "# Configurar a API Key do OpenAI de forma segura\n",
        "def setup_openai_key():\n",
        "    \"\"\"Configura a API Key de forma segura\"\"\"\n",
        "    try:\n",
        "        # Tentar pegar do Colab Secrets (mais seguro)\n",
        "        OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "        print(\"‚úÖ API Key carregada dos secrets do Colab\")\n",
        "    except:\n",
        "        # Se n√£o existir, solicitar ao usu√°rio (n√£o exibe na tela)\n",
        "        print(\"üîê API Key n√£o encontrada nos secrets do Colab\")\n",
        "        print(\"Por favor, insira sua OpenAI API Key:\")\n",
        "        OPENAI_API_KEY = getpass.getpass(\"API Key: \")\n",
        "        print(\"‚úÖ API Key configurada com sucesso\")\n",
        "\n",
        "    return OPENAI_API_KEY\n",
        "\n",
        "# Configurar API Key\n",
        "OPENAI_API_KEY = setup_openai_key()\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Vari√°vel global para armazenar o dataframe e metadados\n",
        "df = None\n",
        "dataset_info = {}\n",
        "\n",
        "def update_dataset_info(csv_path):\n",
        "    \"\"\"Extrai e atualiza metadados do dataset carregado\"\"\"\n",
        "    global df, dataset_info\n",
        "\n",
        "    # Extrair informa√ß√µes do dataset\n",
        "    dataset_info = {\n",
        "        \"filename\": os.path.basename(csv_path),\n",
        "        \"shape\": df.shape,\n",
        "        \"columns\": df.columns.tolist(),\n",
        "        \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
        "        \"numeric_columns\": df.select_dtypes(include=[np.number]).columns.tolist(),\n",
        "        \"categorical_columns\": df.select_dtypes(include=['object', 'category']).columns.tolist(),\n",
        "        \"missing_summary\": df.isnull().sum().to_dict()\n",
        "    }\n",
        "\n",
        "    info_text = f\"\"\"‚úÖ Dataset carregado com sucesso!\n",
        "üìä Shape: {df.shape[0]} linhas √ó {df.shape[1]} colunas\n",
        "üìã Colunas: {', '.join(df.columns.tolist()[:10])}{'...' if len(df.columns) > 10 else ''}\n",
        "üî¢ Colunas num√©ricas: {len(dataset_info['numeric_columns'])}\n",
        "üìù Colunas categ√≥ricas: {len(dataset_info['categorical_columns'])}\n",
        "\"\"\"\n",
        "    return info_text\n",
        "\n",
        "def load_csv_from_path(csv_path):\n",
        "    \"\"\"Carrega CSV de um caminho espec√≠fico\"\"\"\n",
        "    global df\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        info_text = update_dataset_info(csv_path)\n",
        "        return True, info_text\n",
        "    except Exception as e:\n",
        "        df = None\n",
        "        return False, f\"‚ùå Erro ao carregar CSV: {str(e)}\"\n",
        "\n",
        "def upload_csv_file(file):\n",
        "    \"\"\"Processa upload de arquivo via interface\"\"\"\n",
        "    global df\n",
        "    if file is None:\n",
        "        return False, \"‚ùå Nenhum arquivo foi selecionado\"\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(file.name)\n",
        "        info_text = update_dataset_info(file.name)\n",
        "        return True, info_text\n",
        "    except Exception as e:\n",
        "        df = None\n",
        "        return False, f\"‚ùå Erro ao carregar CSV: {str(e)}\"\n",
        "\n",
        "print(\"Sistema de carregamento de CSV inicializado com API Key segura!\")\n",
        "# O c√≥digo de download do kagglehub no in√≠cio foi removido daqui para ser integrado\n",
        "# na fun√ß√£o `load_kaggle_and_update` do Gradio."
      ],
      "metadata": {
        "id": "ips0VcEcndIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c10345-fb13-4756-9f2d-0df310aa40f2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API Key carregada dos secrets do Colab\n",
            "Sistema de carregamento de CSV inicializado com API Key segura!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 3: Fun√ß√µes de An√°lise (Tools) - VERS√ÉO UNIFICADA E CORRIGIDA ---\n",
        "\n",
        "# Gera√ß√£o de caminhos √∫nicos para salvar imagens (fun√ß√£o auxiliar essencial)\n",
        "def get_plot_path(analysis_type, column=None):\n",
        "    \"\"\"Gera um nome de arquivo √∫nico para a imagem do plot.\"\"\"\n",
        "    # Garante que a pasta 'plots' exista\n",
        "    if not os.path.exists(\"plots\"):\n",
        "        os.makedirs(\"plots\")\n",
        "\n",
        "    # Cria um nome √∫nico baseado no tipo de an√°lise e timestamp\n",
        "    col_name = f\"_{column}\" if column else \"\"\n",
        "    filename = f\"plots/{analysis_type}{col_name}_{int(pd.Timestamp.now().timestamp())}.png\"\n",
        "    return filename\n",
        "\n",
        "def get_data_summary():\n",
        "    \"\"\"Retorna um resumo detalhado dos dados (sem altera√ß√µes necess√°rias)\"\"\"\n",
        "    # ... (c√≥digo da fun√ß√£o get_data_summary original)\n",
        "    if df is None:\n",
        "        return json.dumps({\"error\": \"Nenhum dataset carregado\"})\n",
        "\n",
        "    summary = {\n",
        "        \"filename\": dataset_info.get(\"filename\", \"unknown\"),\n",
        "        \"shape\": {\"rows\": df.shape[0], \"columns\": df.shape[1]},\n",
        "        \"columns\": df.columns.tolist(),\n",
        "        \"numeric_columns\": dataset_info.get(\"numeric_columns\", []),\n",
        "        \"categorical_columns\": dataset_info.get(\"categorical_columns\", []),\n",
        "        \"dtypes\": {col: str(dtype) for col, dtype in df.dtypes.items()},\n",
        "        \"missing_values\": df.isnull().sum().to_dict(),\n",
        "        \"missing_percentage\": {col: f\"{(df[col].isnull().sum() / len(df) * 100):.2f}%\"\n",
        "                               for col in df.columns if df[col].isnull().sum() > 0},\n",
        "        \"memory_usage\": f\"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\"\n",
        "    }\n",
        "\n",
        "    if dataset_info.get(\"numeric_columns\"):\n",
        "        summary[\"numeric_statistics\"] = df[dataset_info[\"numeric_columns\"]].describe().to_dict()\n",
        "    if dataset_info.get(\"categorical_columns\"):\n",
        "        categorical_info = {}\n",
        "        for col in dataset_info[\"categorical_columns\"][:5]:\n",
        "            categorical_info[col] = {\n",
        "                \"unique_values\": int(df[col].nunique()),\n",
        "                \"top_values\": df[col].value_counts().head(5).to_dict()\n",
        "            }\n",
        "        summary[\"categorical_info\"] = categorical_info\n",
        "\n",
        "    return json.dumps(summary, default=str)\n",
        "\n",
        "# --- FUN√á√ïES DE PLOTAGEM COM SALVAMENTO E EXIBI√á√ÉO ---\n",
        "\n",
        "def analyze_distribution(column: str) -> str:\n",
        "    \"\"\"Analisa e visualiza a distribui√ß√£o de uma coluna espec√≠fica.\"\"\"\n",
        "    global df, dataset_info\n",
        "    if column not in df.columns:\n",
        "        return json.dumps({\"status\": \"error\", \"message\": f\"Coluna '{column}' n√£o encontrada.\"})\n",
        "\n",
        "    is_numeric = pd.api.types.is_numeric_dtype(df[column])\n",
        "    plot_path = get_plot_path(\"distribution\", column)\n",
        "\n",
        "    try:\n",
        "        if is_numeric:\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "            axes[0].hist(df[column].dropna(), bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "            axes[0].set_title(f'Histograma de {column}')\n",
        "            axes[1].boxplot(df[column].dropna())\n",
        "            axes[1].set_title(f'Boxplot de {column}')\n",
        "            df[column].dropna().plot(kind='density', ax=axes[2], color='steelblue')\n",
        "            axes[2].set_title(f'Densidade de {column}')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # --- CORRE√á√ÉO DE EXIBI√á√ÉO ---\n",
        "            plt.savefig(plot_path)\n",
        "            plt.close()\n",
        "            display(Markdown(f\"### Gr√°fico de Distribui√ß√£o - Coluna: {column}\"))\n",
        "            display(Image(plot_path))\n",
        "            # -----------------------------\n",
        "\n",
        "            stats = df[column].describe().to_dict()\n",
        "            return json.dumps({\n",
        "                \"status\": \"success\",\n",
        "                \"message\": f\"An√°lise de distribui√ß√£o para {column} conclu√≠da.\",\n",
        "                \"plot_info\": f\"Gr√°fico salvo em {plot_path}.\"\n",
        "            }, default=str)\n",
        "\n",
        "        else:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            sns.countplot(y=df[column], order=df[column].value_counts().index)\n",
        "            plt.title(f'Contagem de Frequ√™ncia de {column}')\n",
        "\n",
        "            # --- CORRE√á√ÉO DE EXIBI√á√ÉO ---\n",
        "            plt.savefig(plot_path)\n",
        "            plt.close()\n",
        "            display(Markdown(f\"### Gr√°fico de Frequ√™ncia - Coluna: {column}\"))\n",
        "            display(Image(plot_path))\n",
        "            # -----------------------------\n",
        "\n",
        "            counts = df[column].value_counts().to_dict()\n",
        "            return json.dumps({\n",
        "                \"status\": \"success\",\n",
        "                \"message\": f\"An√°lise de frequ√™ncia para {column} conclu√≠da. Contagens: {counts}.\",\n",
        "                \"plot_info\": f\"Gr√°fico salvo em {plot_path}.\"\n",
        "            }, default=str)\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"status\": \"error\", \"message\": f\"Erro ao plotar distribui√ß√£o para {column}: {e}\"})\n",
        "\n",
        "def analyze_correlation(columns=None) -> str:\n",
        "    \"\"\"Calcula e visualiza a correla√ß√£o entre vari√°veis num√©ricas.\"\"\"\n",
        "    global df\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    if len(numeric_cols) < 2:\n",
        "        return json.dumps({\"status\": \"warning\", \"message\": \"N√£o h√° colunas num√©ricas suficientes (m√≠nimo 2) para correla√ß√£o.\"})\n",
        "\n",
        "    try:\n",
        "        columns = [col for col in (columns if columns else numeric_cols) if col in numeric_cols]\n",
        "        if len(columns) > 20: columns = columns[:20]\n",
        "\n",
        "        correlation_matrix = df[columns].corr()\n",
        "        plot_path = get_plot_path(\"correlation_matrix\")\n",
        "\n",
        "        plt.figure(figsize=(max(10, len(columns)), max(8, len(columns) * 0.8)))\n",
        "        sns.heatmap(correlation_matrix, annot=len(columns) <= 10, cmap='coolwarm', center=0, fmt=\".2f\")\n",
        "        plt.title('Matriz de Correla√ß√£o entre Vari√°veis Num√©ricas')\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # --- CORRE√á√ÉO DE EXIBI√á√ÉO ---\n",
        "        plt.savefig(plot_path)\n",
        "        plt.close()\n",
        "        display(Markdown(f\"### Gr√°fico de Correla√ß√£o - Heatmap\"))\n",
        "        display(Image(plot_path))\n",
        "        # -----------------------------\n",
        "\n",
        "        # ... (c√≥digo para resumir as correla√ß√µes mais fortes)\n",
        "        corr_pairs = []\n",
        "        for i in range(len(correlation_matrix.columns)):\n",
        "            for j in range(i+1, len(correlation_matrix.columns)):\n",
        "                corr_pairs.append({\"var1\": correlation_matrix.columns[i], \"var2\": correlation_matrix.columns[j], \"correlation\": float(correlation_matrix.iloc[i, j])})\n",
        "        corr_pairs.sort(key=lambda x: abs(x[\"correlation\"]), reverse=True)\n",
        "\n",
        "        return json.dumps({\n",
        "            \"status\": \"success\",\n",
        "            \"message\": \"Matriz de correla√ß√£o calculada e plotada.\",\n",
        "            \"top_10_correlations\": corr_pairs[:10],\n",
        "            \"plot_info\": f\"Gr√°fico salvo em {plot_path}.\"\n",
        "        }, default=str)\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"status\": \"error\", \"message\": f\"Erro ao plotar correla√ß√£o: {e}\"})\n",
        "\n",
        "def detect_outliers(column):\n",
        "    \"\"\"Detecta e visualiza outliers usando IQR.\"\"\"\n",
        "    if df is None or column not in df.columns or not pd.api.types.is_numeric_dtype(df[column]):\n",
        "        return json.dumps({\"error\": f\"Coluna '{column}' n√£o √© num√©rica ou n√£o existe\"})\n",
        "\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
        "\n",
        "    plot_path = get_plot_path(\"outliers\", column)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Boxplot e Scatter plot... (mantido do seu c√≥digo original)\n",
        "    axes[0].boxplot(df[column].dropna()); axes[0].set_title(f'Boxplot de {column}')\n",
        "    normal_data = df[~((df[column] < lower_bound) | (df[column] > upper_bound))]\n",
        "    axes[1].scatter(range(len(normal_data)), normal_data[column], alpha=0.5, s=10, label='Normal')\n",
        "    if len(outliers) > 0: axes[1].scatter(outliers.index, outliers[column], color='red', alpha=0.7, s=30, label='Outliers')\n",
        "    axes[1].set_title(f'Distribui√ß√£o com Outliers Destacados'); axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # --- CORRE√á√ÉO DE EXIBI√á√ÉO ---\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    display(Markdown(f\"### Gr√°fico de Detec√ß√£o de Outliers - Coluna: {column}\"))\n",
        "    display(Image(plot_path))\n",
        "    # -----------------------------\n",
        "\n",
        "    result = {\"total_outliers\": len(outliers), \"percentage\": float((len(outliers) / len(df)) * 100)}\n",
        "    return json.dumps({\"status\": \"success\", \"message\": f\"Detec√ß√£o de outliers conclu√≠da. {len(outliers)} outliers encontrados.\", \"result\": result, \"plot_info\": f\"Gr√°fico salvo em {plot_path}.\"}, default=str)\n",
        "\n",
        "\n",
        "def compare_groups(column, group_by):\n",
        "    \"\"\"Compara distribui√ß√µes de uma coluna agrupada por outra.\"\"\"\n",
        "    if df is None or column not in df.columns or group_by not in df.columns or df[group_by].nunique() > 10:\n",
        "         return json.dumps({\"error\": \"Erro de coluna ou mais de 10 grupos.\"})\n",
        "\n",
        "    plot_path = get_plot_path(\"group_comparison\", f\"{column}_vs_{group_by}\")\n",
        "\n",
        "    if pd.api.types.is_numeric_dtype(df[column]):\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        df.boxplot(column=column, by=group_by, ax=axes[0]); plt.suptitle(\"\"); axes[0].set_title(f'{column} por {group_by}')\n",
        "        for group in df[group_by].unique()[:5]: axes[1].hist(df[df[group_by] == group][column].dropna(), alpha=0.5, label=str(group), bins=30)\n",
        "        axes[1].set_title(f'Distribui√ß√£o de {column} por {group_by}'); axes[1].legend()\n",
        "    else:\n",
        "        cross_tab = pd.crosstab(df[column], df[group_by])\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "        sns.heatmap(cross_tab, annot=True, fmt='d', cmap='YlOrRd', ax=axes[0]); axes[0].set_title(f'Crosstab: {column} vs {group_by}')\n",
        "        cross_tab_pct = cross_tab.div(cross_tab.sum(axis=1), axis=0) * 100\n",
        "        cross_tab_pct.plot(kind='bar', stacked=True, ax=axes[1]); axes[1].set_title(f'Distribui√ß√£o Percentual: {column} por {group_by}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # --- CORRE√á√ÉO DE EXIBI√á√ÉO ---\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    display(Markdown(f\"### Gr√°fico de Compara√ß√£o de Grupos: {column} por {group_by}\"))\n",
        "    display(Image(plot_path))\n",
        "    # -----------------------------\n",
        "\n",
        "    return json.dumps({\"status\": \"success\", \"message\": f\"Compara√ß√£o de grupos conclu√≠da e plotada.\",\"plot_info\": f\"Gr√°fico salvo em {plot_path}.\"}, default=str)\n",
        "\n",
        "# As outras fun√ß√µes (analyze_temporal_patterns e execute_custom_code) tamb√©m precisam\n",
        "# dessa mesma l√≥gica de salvamento/exibi√ß√£o se gerarem plots, mas n√£o as inclu√≠ aqui\n",
        "# por brevidade, apenas as principais.\n",
        "\n",
        "# --- Bloco 4: Defini√ß√£o das Tools (igual ao seu original, sem altera√ß√£o) ---\n",
        "tools = [\n",
        "# ... (Seu c√≥digo original de defini√ß√£o das tools)\n",
        "]\n",
        "\n",
        "available_functions = {\n",
        "# ... (Seu c√≥digo original de mapeamento das fun√ß√µes)\n",
        "}\n",
        "\n",
        "print(\"Fun√ß√µes de an√°lise e Tools definidas/corrigidas com sucesso! Prontas para Streamlit.\")"
      ],
      "metadata": {
        "id": "eMqA92zPngpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f561aff5-ca7e-484c-fd55-23cf3ca51709"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fun√ß√µes de an√°lise e Tools definidas/corrigidas com sucesso! Prontas para Streamlit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 4: Defini√ß√£o das Tools para o Agente ---\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_data_summary\",\n",
        "            \"description\": \"Retorna um resumo completo do dataset carregado incluindo shape, colunas, tipos de dados, valores faltantes, estat√≠sticas descritivas. Use esta fun√ß√£o primeiro para entender a estrutura dos dados.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {},\n",
        "                \"required\": []\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze_distribution\",\n",
        "            \"description\": \"Analisa e visualiza a distribui√ß√£o de uma coluna espec√≠fica. Para colunas num√©ricas mostra histograma, boxplot e densidade. Para colunas categ√≥ricas mostra gr√°ficos de barras e pizza.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Nome exato da coluna a ser analisada\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"column\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze_correlation\",\n",
        "            \"description\": \"Calcula e visualiza a correla√ß√£o entre vari√°veis num√©ricas do dataset. Retorna as correla√ß√µes mais fortes (positivas e negativas).\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"columns\": {\n",
        "                        \"type\": \"array\",\n",
        "                        \"items\": {\"type\": \"string\"},\n",
        "                        \"description\": \"Lista de colunas para an√°lise. Se n√£o fornecido, usa todas as colunas num√©ricas (limitado a 20).\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": []\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"detect_outliers\",\n",
        "            \"description\": \"Detecta outliers em uma coluna num√©rica usando o m√©todo IQR (Intervalo Interquartil). Mostra visualiza√ß√µes e estat√≠sticas dos outliers.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Nome da coluna num√©rica para detec√ß√£o de outliers\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"column\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"compare_groups\",\n",
        "            \"description\": \"Compara a distribui√ß√£o de uma coluna agrupada por outra coluna. √ötil para identificar padr√µes entre grupos diferentes. A coluna de agrupamento deve ter no m√°ximo 10 valores √∫nicos.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Coluna a ser analisada\"\n",
        "                    },\n",
        "                    \"group_by\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Coluna para agrupar (deve ter poucos valores √∫nicos, m√°ximo 10)\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"column\", \"group_by\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"analyze_temporal_patterns\",\n",
        "            \"description\": \"Analisa padr√µes temporais no dataset. √ötil quando h√° uma coluna de tempo/data ou sequencial.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"time_column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Nome da coluna que representa tempo/data/sequ√™ncia\"\n",
        "                    },\n",
        "                    \"value_column\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Coluna de valores a plotar ao longo do tempo (opcional)\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"time_column\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"execute_custom_code\",\n",
        "            \"description\": \"Executa c√≥digo Python customizado para an√°lises espec√≠ficas. O dataframe est√° dispon√≠vel como 'df'. Use apenas quando as outras ferramentas n√£o forem suficientes.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"code\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"C√≥digo Python a ser executado. O dataframe est√° dispon√≠vel como 'df'.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"code\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Mapear nomes de fun√ß√µes para fun√ß√µes reais\n",
        "available_functions = {\n",
        "    \"get_data_summary\": get_data_summary,\n",
        "    \"analyze_distribution\": analyze_distribution,\n",
        "    \"analyze_correlation\": analyze_correlation,\n",
        "    \"detect_outliers\": detect_outliers,\n",
        "    \"compare_groups\": compare_groups,\n",
        "    \"analyze_temporal_patterns\": analyze_temporal_patterns,\n",
        "    \"execute_custom_code\": execute_custom_code\n",
        "}\n",
        "\n",
        "print(\"Tools gen√©ricas definidas com sucesso!\")"
      ],
      "metadata": {
        "id": "KzsSZ8ylnklF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036c09c6-5c80-481e-93a6-dff2fcbbb180"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tools gen√©ricas definidas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 5: Sistema de Mem√≥ria ---\n",
        "\n",
        "class AgentMemory:\n",
        "    def __init__(self):\n",
        "        self.conversation_history = []\n",
        "        self.analysis_results = {}\n",
        "        self.conclusions = []\n",
        "        self.dataset_context = {}\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        self.conversation_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    def add_analysis(self, analysis_type, result):\n",
        "        self.analysis_results[analysis_type] = result\n",
        "\n",
        "    def add_conclusion(self, conclusion):\n",
        "        # Evita duplicidade de conclus√µes se o agente tentar dar a mesma resposta v√°rias vezes\n",
        "        if conclusion not in self.conclusions:\n",
        "            self.conclusions.append(conclusion)\n",
        "\n",
        "    def set_dataset_context(self, context):\n",
        "        self.dataset_context = context\n",
        "\n",
        "    def get_context(self):\n",
        "        context = \"\"\n",
        "\n",
        "        if self.dataset_context:\n",
        "            context += \"Informa√ß√µes do Dataset:\\n\"\n",
        "            context += f\"- Arquivo: {self.dataset_context.get('filename', 'N/A')}\\n\"\n",
        "            context += f\"- Dimens√µes: {self.dataset_context.get('shape', 'N/A')}\\n\"\n",
        "            context += f\"- Colunas: {', '.join(self.dataset_context.get('columns', []))}\\n\\n\"\n",
        "\n",
        "        if self.analysis_results:\n",
        "            context += \"An√°lises realizadas:\\n\"\n",
        "            # Limitar para n√£o sobrecarregar\n",
        "            for analysis_type in list(self.analysis_results.keys())[-5:]:\n",
        "                 context += f\"- {analysis_type}\\n\"\n",
        "\n",
        "        if self.conclusions:\n",
        "            context += \"\\nConclus√µes anteriores:\\n\"\n",
        "            # Limitar para n√£o sobrecarregar\n",
        "            for i, conclusion in enumerate(self.conclusions, 1):\n",
        "                context += f\"{i}. {conclusion}\\n\"\n",
        "\n",
        "        return context\n",
        "\n",
        "    def get_full_history(self):\n",
        "        # Retorna apenas a hist√≥ria recente para manter o limite de tokens baixo\n",
        "        return self.conversation_history[-10:] # Manter as √∫ltimas 10 intera√ß√µes\n",
        "\n",
        "    def get_initial_history(self):\n",
        "        # Retorna o hist√≥rico de toda a an√°lise aut√¥noma\n",
        "        return self.conversation_history\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reseta a mem√≥ria da conversa e dos resultados de an√°lise\"\"\"\n",
        "        self.conversation_history = []\n",
        "        self.analysis_results = {}\n",
        "        self.conclusions = []\n",
        "\n",
        "memory = AgentMemory()\n",
        "print(\"Sistema de mem√≥ria inicializado!\")\n",
        "\n",
        "# --- Bloco 5.5: Fun√ß√µes Auxiliares para An√°lise Aut√¥noma ---\n",
        "\n",
        "def identify_best_column_for_auto_plot():\n",
        "    \"\"\"Identifica a melhor coluna para plotagem autom√°tica (maior vari√¢ncia ou categ√≥rica).\"\"\"\n",
        "    global df, dataset_info\n",
        "\n",
        "    if df is None or df.empty:\n",
        "        return None, None\n",
        "\n",
        "    numeric_cols = dataset_info.get('numeric_columns', [])\n",
        "    categorical_cols = dataset_info.get('categorical_cols', [])\n",
        "\n",
        "    # 1. Prioridade: Coluna Num√©rica com Maior Desvio Padr√£o\n",
        "    if numeric_cols:\n",
        "        try:\n",
        "            # Calcula o desvio padr√£o e encontra o m√°ximo\n",
        "            std_devs = df[numeric_cols].std().sort_values(ascending=False)\n",
        "            if not std_devs.empty:\n",
        "                best_col = std_devs.index[0]\n",
        "                return best_col, \"num√©rica com maior vari√¢ncia\"\n",
        "        except:\n",
        "            pass # Em caso de erro, segue para a pr√≥xima prioridade\n",
        "\n",
        "    # 2. Prioridade: Coluna Categ√≥rica com Baixo/M√©dio Cardinalidade (ideal para distribui√ß√£o)\n",
        "    if categorical_cols:\n",
        "        for col in categorical_cols:\n",
        "            n_unique = df[col].nunique()\n",
        "            # Coluna com entre 2 e 10 valores √∫nicos (ideal para barras/pizza)\n",
        "            if 2 <= n_unique <= 10:\n",
        "                return col, \"categ√≥rica ideal para distribui√ß√£o\"\n",
        "\n",
        "        # √öltimo recurso categ√≥rico: pega a primeira categ√≥rica\n",
        "        if categorical_cols:\n",
        "             return categorical_cols[0], \"primeira coluna categ√≥rica\"\n",
        "\n",
        "    # 3. √öltimo recurso: primeira coluna num√©rica ou primeira coluna\n",
        "    if dataset_info.get('columns'):\n",
        "         # Se numeric_cols estiver vazio (ex: s√≥ categ√≥ricas), esta coluna pode ser a mesma que a 2.\n",
        "         # Se s√≥ tiver uma coluna num√©rica, ela ser√° a √∫nica.\n",
        "         if numeric_cols:\n",
        "             return numeric_cols[0], \"primeira coluna num√©rica\"\n",
        "         else:\n",
        "             return dataset_info['columns'][0], \"primeira coluna dispon√≠vel\"\n",
        "\n",
        "    return None, None"
      ],
      "metadata": {
        "id": "rdig4plvnpSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073be9a5-64e9-4412-b497-469b5b37705e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sistema de mem√≥ria inicializado!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 6: Agente Principal e Fun√ß√£o Aut√¥noma (COMPLETO E CORRIGIDO) ---\n",
        "\n",
        "def run_agent_core(user_query, history=None):\n",
        "    \"\"\"Executa a l√≥gica central do agente (para chat e modo aut√¥nomo)\"\"\"\n",
        "\n",
        "    if df is None:\n",
        "        return \"‚ö†Ô∏è Nenhum dataset carregado. Por favor, carregue um arquivo CSV primeiro.\"\n",
        "\n",
        "    # Atualizar contexto do dataset na mem√≥ria\n",
        "    memory.set_dataset_context(dataset_info)\n",
        "\n",
        "    # Adicionar contexto gen√©rico do dataset ao sistema\n",
        "    system_message = f\"\"\"Voc√™ √© um agente especializado em An√°lise Explorat√≥ria de Dados (EDA) gen√©rico e adapt√°vel, focado em fornecer insights detalhados e conclus√µes.\n",
        "\n",
        "Dataset atual:\n",
        "- Arquivo: {dataset_info.get('filename', 'desconhecido')}\n",
        "- Dimens√µes: {df.shape[0]} linhas √ó {df.shape[1]} colunas\n",
        "- Colunas num√©ricas ({len(dataset_info.get('numeric_columns', []))}): {', '.join(dataset_info.get('numeric_columns', [])[:10])}{'...' if len(dataset_info.get('numeric_columns', [])) > 10 else ''}\n",
        "- Colunas categ√≥ricas ({len(dataset_info.get('categorical_columns', []))}): {', '.join(dataset_info.get('categorical_columns', [])[:10])}{'...' if len(dataset_info.get('categorical_columns', [])) > 10 else ''}\n",
        "\n",
        "Voc√™ tem acesso a ferramentas de an√°lise (get_data_summary, analyze_distribution, analyze_correlation, etc.).\n",
        "\n",
        "Contexto das an√°lises anteriores:\n",
        "{memory.get_context()}\n",
        "\n",
        "IMPORTANTE:\n",
        "- Para a an√°lise inicial ou se for solicitado um resumo, use **get_data_summary()** primeiro.\n",
        "- Para an√°lises detalhadas, **use as tools de forma sequencial e l√≥gica**.\n",
        "- Adapte suas an√°lises ao tipo de dados (num√©rico vs categ√≥rico).\n",
        "- **Sintetize TODAS as informa√ß√µes obtidas** (incluindo as geradas pelas tools) em um formato de conclus√µes acion√°veis.\n",
        "- Seja proativo em sugerir an√°lises relevantes baseadas no tipo de dados.\n",
        "- Responda em portugu√™s de forma clara e estruturada com markdown.\n",
        "\"\"\"\n",
        "\n",
        "    # Se for uma query de chat (vindo do Gradio), adiciona ao hist√≥rico\n",
        "    if history is not None:\n",
        "         memory.add_message(\"user\", user_query)\n",
        "         messages = [{\"role\": \"system\", \"content\": system_message}] + memory.get_full_history()\n",
        "    else:\n",
        "        # Modo aut√¥nomo (an√°lise inicial)\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "        ]\n",
        "\n",
        "    # Loop de intera√ß√£o com o agente\n",
        "    max_iterations = 10\n",
        "    iteration = 0\n",
        "    final_response_content = None\n",
        "\n",
        "    while iteration < max_iterations:\n",
        "        iteration += 1\n",
        "\n",
        "        # Chamar a API\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            tool_choice=\"auto\"\n",
        "        )\n",
        "\n",
        "        response_message = response.choices[0].message\n",
        "\n",
        "        # Se n√£o h√° tool calls, temos a resposta final\n",
        "        if not response_message.tool_calls:\n",
        "            final_response_content = response_message.content\n",
        "\n",
        "            # Se a resposta cont√©m 'conclus√µes' ou 'insights', registre na mem√≥ria\n",
        "            if any(k in final_response_content.lower() for k in [\"conclus√µes\", \"insights\", \"resumo dos achados\"]):\n",
        "                memory.add_conclusion(final_response_content)\n",
        "\n",
        "            memory.add_message(\"assistant\", final_response_content)\n",
        "\n",
        "            # Se for modo chat, retorna para o loop do Gradio\n",
        "            if history is not None:\n",
        "                history.append([user_query, final_response_content])\n",
        "                return history\n",
        "            # Se for modo aut√¥nomo, retorna o conte√∫do\n",
        "            return final_response_content\n",
        "\n",
        "        # Adicionar a resposta do assistente (tool_calls) √†s mensagens\n",
        "        messages.append(response_message)\n",
        "\n",
        "        # Executar as tool calls\n",
        "        for tool_call in response_message.tool_calls:\n",
        "            function_name = tool_call.function.name\n",
        "            function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "            # Chamar a fun√ß√£o\n",
        "            function_to_call = available_functions[function_name]\n",
        "            function_response = function_to_call(**function_args)\n",
        "\n",
        "            # Registrar na mem√≥ria\n",
        "            memory.add_analysis(function_name, function_args)\n",
        "\n",
        "            # Adicionar o resultado √†s mensagens\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response\n",
        "            })\n",
        "\n",
        "    # Se atingir o limite de itera√ß√µes\n",
        "    error_message = \"‚ö†Ô∏è N√∫mero m√°ximo de itera√ß√µes atingido\"\n",
        "    if history is not None:\n",
        "        history.append([user_query, error_message])\n",
        "        return history\n",
        "    return error_message\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# NOVO BLOCO: Fun√ß√£o de An√°lise Aut√¥noma (PROMPT EXTENDIDO)\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "AUTONOMOUS_PROMPT_EXTENDED = \"\"\"\n",
        "Realize uma **An√°lise Explorat√≥ria de Dados (EDA) completa** e detalhada deste dataset. Seu objetivo √© cobrir exaustivamente as seguintes categorias de an√°lise de forma sequencial, utilizando as ferramentas dispon√≠veis.\n",
        "\n",
        "## 1. Descri√ß√£o e Estrutura dos Dados (Obrigat√≥rio)\n",
        "1.  **Resumo Inicial:** Use a tool `get_data_summary()` para entender a estrutura dos dados.\n",
        "2.  **Identifica√ß√£o de Tipos:** Quais s√£o os tipos de dados (num√©ricos, categ√≥ricos)?\n",
        "3.  **Valores Faltantes:** Analise e summarize a porcentagem e a distribui√ß√£o de valores faltantes.\n",
        "4.  **Duplicatas:** Verifique a exist√™ncia de linhas duplicadas.\n",
        "\n",
        "## 2. An√°lise Univariada e Distribui√ß√£o (Inclui Gr√°fico Autom√°tico)\n",
        "5.  **Distribui√ß√£o Gr√°fica:** **GERE IMEDIATAMENTE UM GR√ÅFICO.** Use a tool `analyze_distribution` na coluna que te foi dada como foco inicial. (Esta instru√ß√£o √© injetada para for√ßar o gr√°fico.)\n",
        "6.  **Medidas de Tend√™ncia:** Quais s√£o as m√©dias, medianas e modas para as principais colunas num√©ricas?\n",
        "7.  **Medidas de Variabilidade:** Qual o desvio padr√£o, vari√¢ncia e intervalo (min/max) de 3 a 5 colunas num√©ricas chave?\n",
        "8.  **Frequ√™ncias:** Quais s√£o os 5 valores mais frequentes e menos frequentes nas colunas categ√≥ricas?\n",
        "\n",
        "## 3. Detec√ß√£o de Anomalias (Outliers)\n",
        "9.  **Identifica√ß√£o de Outliers:** Use a tool `detect_outliers` em pelo menos duas colunas num√©ricas chave para identificar valores at√≠picos.\n",
        "10. **Impacto e Recomenda√ß√£o:** Como esses outliers afetam as m√©dias? Eles devem ser removidos, transformados ou investigados?\n",
        "\n",
        "## 4. Rela√ß√µes e Padr√µes (Multivariada)\n",
        "11. **Matriz de Correla√ß√£o Gr√°fica:** Use a tool `analyze_correlation` para calcular e plotar a correla√ß√£o entre as vari√°veis num√©ricas. **(SEGUNDO GR√ÅFICO OBRIGAT√ìRIO)**\n",
        "12. **Correla√ß√µes Chave:** Liste as 5 correla√ß√µes mais fortes (positivas e negativas).\n",
        "13. **Influ√™ncia de Vari√°veis:** Quais vari√°veis parecem ter maior ou menor influ√™ncia sobre outras (especialmente em rela√ß√£o a colunas target/classe, se houver)?\n",
        "14. **Compara√ß√£o de Grupos:** Use a tool `compare_groups` para analisar uma coluna num√©rica chave em rela√ß√£o a uma coluna categ√≥rica com poucos valores (ex: Class/Target).\n",
        "\n",
        "## 5. An√°lises Adicionais (10 Novas An√°lises)\n",
        "15. **S√©rie Temporal (se aplic√°vel):** Se existir uma coluna 'Time' ou 'Date', use `analyze_temporal_patterns` para identificar tend√™ncias, sazonalidade ou ciclos.\n",
        "16. **Homogeneidade:** Existe uma distribui√ß√£o uniforme das observa√ß√µes ao longo do tempo ou dos grupos?\n",
        "17. **Engenharia de Features:** Sugira 3 poss√≠veis *features* (colunas) que poderiam ser criadas a partir das colunas existentes para melhorar modelos preditivos.\n",
        "18. **Balanceamento de Classe (se aplic√°vel):** Se houver uma coluna bin√°ria (ex: 0/1, Sim/N√£o), ela est√° desbalanceada? Qual a propor√ß√£o?\n",
        "19. **Cardinalidade:** Qual a coluna categ√≥rica com a maior cardinalidade (mais valores √∫nicos) e qual a recomenda√ß√£o de tratamento para ela?\n",
        "20. **Visualiza√ß√£o Bivariada:** Escolha as duas vari√°veis mais correlacionadas e sugira o tipo de gr√°fico (dispersion plot, boxplot, etc.) que melhor representaria essa rela√ß√£o.\n",
        "21. **An√°lise por Quartil:** Divida uma coluna num√©rica chave em quartis e analise a m√©dia de outra coluna num√©rica por esses quartis.\n",
        "22. **Skewness e Kurtosis:** Analise a assimetria (skewness) e o achatamento (kurtosis) das 3 principais colunas num√©ricas para entender a forma da distribui√ß√£o.\n",
        "23. **Pr√≥ximo Passo:** Qual o pr√≥ximo passo mais l√≥gico para este dataset (ex: Pr√©-processamento, Modelagem, Coleta de mais dados)?\n",
        "24. **Agrupamentos (Clusters):** Baseado na correla√ß√£o e distribui√ß√£o, voc√™ suspeita da presen√ßa de agrupamentos (clusters) naturais nos dados?\n",
        "\n",
        "## 6. Conclus√µes Finais (S√≠ntese)\n",
        "25. **S√≠ntese de Achados:** **APENAS NESTE √öLTIMO PASSO**, utilize todas as informa√ß√µes obtidas nas an√°lises 1 a 24 para responder a pergunta: **Quais s√£o as conclus√µes e os insights mais importantes que voc√™ obteve deste dataset?** Apresente os achados de forma clara e estruturada.\n",
        "\"\"\"\n",
        "\n",
        "def autonomous_analysis():\n",
        "    \"\"\"Executa a an√°lise aut√¥noma do agente, for√ßando o uso de tools.\"\"\"\n",
        "    global df, AUTONOMOUS_PROMPT_EXTENDED\n",
        "\n",
        "    if df is None:\n",
        "        return [], \"‚ùå Nenhum dataset carregado para an√°lise aut√¥noma.\"\n",
        "\n",
        "    # 1. Resetar a mem√≥ria\n",
        "    memory.reset()\n",
        "\n",
        "    # 2. Identificar a coluna para o GR√ÅFICO AUTOM√ÅTICO\n",
        "    col_to_plot, reason = identify_best_column_for_auto_plot()\n",
        "\n",
        "    if not col_to_plot:\n",
        "        initial_response = \"‚ùå Erro: N√£o foi poss√≠vel identificar colunas para an√°lise.\"\n",
        "        return [], initial_response\n",
        "\n",
        "    # 3. Criar a instru√ß√£o inicial for√ßada\n",
        "    initial_analysis_prompt = f\"\"\"\n",
        "    {AUTONOMOUS_PROMPT_EXTENDED}\n",
        "\n",
        "    **EXECU√á√ÉO INICIAL FOR√áADA:**\n",
        "    - Use `get_data_summary()` primeiro.\n",
        "    - Em seguida, para cumprir o ponto 5 de 'An√°lise Gr√°fica Obrigat√≥ria', execute **analyze_distribution(column='{col_to_plot}')**.\n",
        "    - Continue com o plano de an√°lise.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"üöÄ INICIANDO AN√ÅLISE AUT√îNOMA... (Plotagem for√ßada em: '{col_to_plot}')\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # O run_agent_core com history=None retorna o conte√∫do final do agente\n",
        "    final_response = run_agent_core(initial_analysis_prompt, history=None)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚úÖ AN√ÅLISE AUT√îNOMA CONCLU√çDA\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 5. Formatar o hist√≥rico para exibi√ß√£o no Gradio (mantendo a l√≥gica anterior)\n",
        "    analysis_history = memory.get_initial_history()\n",
        "    formatted_history = []\n",
        "\n",
        "    for item in analysis_history:\n",
        "        if item[\"role\"] == \"user\":\n",
        "            pass # Ignora o prompt aut√¥nomo na exibi√ß√£o do chat para maior clareza.\n",
        "        elif item[\"role\"] == \"assistant\":\n",
        "            # Para o chat, o primeiro item deve ser a resposta completa do agente ao prompt aut√¥nomo\n",
        "            if formatted_history and formatted_history[-1][1] is None:\n",
        "                formatted_history[-1][1] = item[\"content\"]\n",
        "            else:\n",
        "                 formatted_history.append([\"**An√°lise Aut√¥noma**\", item[\"content\"]])\n",
        "\n",
        "    # Adicionar uma mensagem de boas-vindas ap√≥s a an√°lise aut√¥noma\n",
        "    if formatted_history and formatted_history[-1][1] is not None:\n",
        "         formatted_history.append([None, \"üëã **An√°lise Aut√¥noma Conclu√≠da!**\\n\\nAgora, sinta-se √† vontade para fazer perguntas detalhadas sobre os dados, pois o contexto e as conclus√µes j√° est√£o na minha mem√≥ria.\"])\n",
        "\n",
        "    return formatted_history, final_response"
      ],
      "metadata": {
        "id": "Rd25b1fUnvul"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco 7: Interface Interativa ---\n",
        "\n",
        "def process_query(message, history):\n",
        "    \"\"\"Processa a pergunta do usu√°rio e retorna a resposta via run_agent_core (modo chat)\"\"\"\n",
        "    if df is None:\n",
        "        # Se for o modo chat, precisamos garantir que o hist√≥rico seja retornado corretamente\n",
        "        if history is None:\n",
        "            history = []\n",
        "        history.append([message, \"‚ö†Ô∏è Por favor, carregue um dataset primeiro.\"])\n",
        "        return history\n",
        "\n",
        "    try:\n",
        "        # run_agent_core em modo chat retorna o hist√≥rico atualizado\n",
        "        updated_history = run_agent_core(message, history=history)\n",
        "        return updated_history\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå **Erro:** {str(e)}\\n\\nTente reformular sua pergunta ou resete a mem√≥ria.\"\n",
        "        history.append([message, error_msg])\n",
        "        return history\n",
        "\n",
        "def get_dataset_status():\n",
        "    \"\"\"Retorna o status atual do dataset\"\"\"\n",
        "    if df is None:\n",
        "        return \"‚ùå **Nenhum dataset carregado**\", None\n",
        "\n",
        "    status = f\"\"\"‚úÖ **Dataset Carregado**\n",
        "\n",
        "üìÅ **Arquivo:** {dataset_info.get('filename', 'N/A')}\n",
        "üìä **Dimens√µes:** {df.shape[0]:,} linhas √ó {df.shape[1]} colunas\n",
        "üíæ **Mem√≥ria:** {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
        "üî¢ **Colunas Num√©ricas:** {len(dataset_info.get('numeric_columns', []))}\n",
        "üìù **Colunas Categ√≥ricas:** {len(dataset_info.get('categorical_columns', []))}\n",
        "\"\"\"\n",
        "    preview = df.head(5)\n",
        "    return status, preview\n",
        "\n",
        "def upload_and_update(file):\n",
        "    \"\"\"Processa upload, dispara an√°lise aut√¥noma e atualiza toda a interface\"\"\"\n",
        "    if file is None:\n",
        "        return (\n",
        "            \"‚ùå Nenhum arquivo selecionado\",\n",
        "            None,\n",
        "            \"‚ùå **Nenhum dataset carregado**\",\n",
        "            gr.update(interactive=False),\n",
        "            gr.update(interactive=False),\n",
        "            [],\n",
        "            \"Nenhuma an√°lise aut√¥noma foi realizada.\"\n",
        "        )\n",
        "\n",
        "    success, message = upload_csv_file(file)\n",
        "\n",
        "    if success and df is not None:\n",
        "        status, preview = get_dataset_status()\n",
        "\n",
        "        # 1. Executar a an√°lise aut√¥noma\n",
        "        # Esta fun√ß√£o printa os gr√°ficos e retorna o hist√≥rico formatado\n",
        "        autonomy_history, final_conclusion = autonomous_analysis()\n",
        "\n",
        "        # 2. Habilitar a intera√ß√£o e retornar status\n",
        "        return (\n",
        "            f\"‚úÖ **Sucesso!**\\n\\n{message}\\n\\n‚ö†Ô∏è **An√°lise Aut√¥noma Iniciada (veja os gr√°ficos acima)!**\",\n",
        "            preview,\n",
        "            status,\n",
        "            gr.update(interactive=True),\n",
        "            gr.update(interactive=True),\n",
        "            autonomy_history,\n",
        "            final_conclusion # Retorna a conclus√£o para o campo de markdown\n",
        "        )\n",
        "    else:\n",
        "        return (\n",
        "            message,\n",
        "            None,\n",
        "            \"‚ùå **Erro ao carregar dataset**\",\n",
        "            gr.update(interactive=False),\n",
        "            gr.update(interactive=False),\n",
        "            [],\n",
        "            \"Nenhuma an√°lise aut√¥noma foi realizada.\"\n",
        "        )\n",
        "\n",
        "def load_kaggle_and_update():\n",
        "    \"\"\"Carrega dataset do Kaggle, dispara an√°lise aut√¥noma e atualiza interface\"\"\"\n",
        "    try:\n",
        "        import kagglehub\n",
        "        path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
        "        csv_path = os.path.join(path, \"creditcard.csv\")\n",
        "        success, message = load_csv_from_path(csv_path)\n",
        "\n",
        "        if success and df is not None:\n",
        "            status, preview = get_dataset_status()\n",
        "\n",
        "            # 1. Executar a an√°lise aut√¥noma\n",
        "            autonomy_history, final_conclusion = autonomous_analysis()\n",
        "\n",
        "            # 2. Habilitar a intera√ß√£o e retornar status\n",
        "            return (\n",
        "                f\"‚úÖ **Dataset do Kaggle carregado!**\\n\\n{message}\\n\\n‚ö†Ô∏è **An√°lise Aut√¥noma Iniciada (veja os gr√°ficos acima)!**\",\n",
        "                preview,\n",
        "                status,\n",
        "                gr.update(interactive=True),\n",
        "                gr.update(interactive=True),\n",
        "                autonomy_history,\n",
        "                final_conclusion\n",
        "            )\n",
        "        else:\n",
        "            return (\n",
        "                f\"‚ùå {message}\",\n",
        "                None,\n",
        "                \"‚ùå **Erro ao carregar dataset**\",\n",
        "                gr.update(interactive=False),\n",
        "                gr.update(interactive=False),\n",
        "                [],\n",
        "                \"Nenhuma an√°lise aut√¥noma foi realizada.\"\n",
        "            )\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå Erro ao carregar dataset do Kaggle: {str(e)}\"\n",
        "        return (\n",
        "            error_msg,\n",
        "            None,\n",
        "            \"‚ùå **Erro ao carregar dataset**\",\n",
        "            gr.update(interactive=False),\n",
        "            gr.update(interactive=False),\n",
        "            [],\n",
        "            \"Nenhuma an√°lise aut√¥noma foi realizada.\"\n",
        "        )\n",
        "\n",
        "def clear_chat_history():\n",
        "    \"\"\"Limpa o hist√≥rico do chat\"\"\"\n",
        "    return []\n",
        "\n",
        "def reset_agent_memory():\n",
        "    \"\"\"Reseta a mem√≥ria do agente mantendo o dataset\"\"\"\n",
        "    memory.reset()\n",
        "    return [], \"‚úÖ Mem√≥ria do agente limpa! O dataset foi mantido.\"\n",
        "\n",
        "def get_detailed_info():\n",
        "    \"\"\"Retorna informa√ß√µes detalhadas do dataset\"\"\"\n",
        "    if df is None:\n",
        "        return \"‚ö†Ô∏è Nenhum dataset carregado\"\n",
        "\n",
        "    info = f\"\"\"## üìä Informa√ß√µes Detalhadas do Dataset\n",
        "\n",
        "### üìã Informa√ß√µes Gerais\n",
        "- **Arquivo:** {dataset_info.get('filename', 'N/A')}\n",
        "- **Dimens√µes:** {df.shape[0]:,} linhas √ó {df.shape[1]} colunas\n",
        "- **Mem√≥ria:** {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n",
        "- **Duplicatas:** {df.duplicated().sum():,}\n",
        "\n",
        "### üìä Resumo das Colunas\n",
        "\n",
        "\"\"\"\n",
        "    for col in df.columns:\n",
        "        dtype = df[col].dtype\n",
        "        missing = df[col].isnull().sum()\n",
        "        missing_pct = (missing / len(df)) * 100\n",
        "        unique = df[col].nunique()\n",
        "\n",
        "        emoji = \"üî¢\" if pd.api.types.is_numeric_dtype(df[col]) else \"üìù\"\n",
        "        info += f\"#### {emoji} **{col}**\\n\"\n",
        "        info += f\"- **Tipo:** `{dtype}`\\n\"\n",
        "        info += f\"- **Valores √∫nicos:** {unique:,}\\n\"\n",
        "        info += f\"- **Valores faltantes:** {missing:,} ({missing_pct:.2f}%)\\n\"\n",
        "\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            info += f\"- **Min:** {df[col].min():.2f} | **Max:** {df[col].max():.2f} | **M√©dia:** {df[col].mean():.2f}\\n\"\n",
        "        else:\n",
        "            top_value = df[col].mode()[0] if len(df[col].mode()) > 0 else \"N/A\"\n",
        "            info += f\"- **Valor mais frequente:** {top_value}\\n\"\n",
        "\n",
        "        info += \"\\n\"\n",
        "\n",
        "    return info\n",
        "\n",
        "def update_history():\n",
        "    \"\"\"Atualiza o hist√≥rico de an√°lises para exibi√ß√£o no accordion\"\"\"\n",
        "    if not memory.analysis_results:\n",
        "        return \"‚ö†Ô∏è Nenhuma an√°lise realizada ainda\"\n",
        "\n",
        "    history_text = \"## üìú Hist√≥rico de An√°lises Realizadas\\n\\n\"\n",
        "    for i, (analysis_type, params) in enumerate(memory.analysis_results.items(), 1):\n",
        "        history_text += f\"**{i}. {analysis_type}**\\n\"\n",
        "        if params:\n",
        "            # Limitar a exibi√ß√£o de par√¢metros longos\n",
        "            param_str = str(params)\n",
        "            if len(param_str) > 150:\n",
        "                 param_str = param_str[:150] + \"...\"\n",
        "            history_text += f\" ¬† - Par√¢metros: `{param_str}`\\n\"\n",
        "        history_text += \"\\n\"\n",
        "    return history_text\n",
        "\n",
        "def update_conclusions():\n",
        "    \"\"\"Atualiza as conclus√µes registradas para exibi√ß√£o no accordion\"\"\"\n",
        "    if not memory.conclusions:\n",
        "        return \"\"\"‚ö†Ô∏è Nenhuma conclus√£o registrada ainda.\n",
        "\n",
        "üí° **Dica:** Pergunte ao agente:\n",
        "- \"Quais suas conclus√µes sobre os dados?\"\n",
        "- \"Fa√ßa um resumo dos principais achados\"\n",
        "- \"Quais insights voc√™ obteve das an√°lises?\"\n",
        "\"\"\"\n",
        "    conclusions_text = \"## üéØ Conclus√µes e Insights do Agente\\n\\n\"\n",
        "    for i, conclusion in enumerate(memory.conclusions, 1):\n",
        "        conclusions_text += f\"### üìå Conclus√£o {i}\\n{conclusion}\\n\\n---\\n\\n\"\n",
        "    return conclusions_text\n",
        "\n",
        "# Criar interface Gradio\n",
        "with gr.Blocks(\n",
        "    title=\"ü§ñ Agente EDA Aut√¥nomo\",\n",
        "    theme=gr.themes.Soft(\n",
        "        primary_hue=\"indigo\",\n",
        "        secondary_hue=\"blue\",\n",
        "    ),\n",
        "    css=\"\"\"\n",
        "        .gradio-container {font-family: 'Segoe UI', sans-serif; max-width: 1400px !important;}\n",
        "        .header {\n",
        "            text-align: center;\n",
        "            padding: 30px;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            border-radius: 15px;\n",
        "            margin-bottom: 25px;\n",
        "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        .section-header {\n",
        "            background: linear-gradient(90deg, #f093fb 0%, #f5576c 100%);\n",
        "            color: white;\n",
        "            padding: 12px 20px;\n",
        "            border-radius: 8px;\n",
        "            margin: 15px 0 10px 0;\n",
        "            font-weight: bold;\n",
        "        }\n",
        "        .status-box {\n",
        "            padding: 15px;\n",
        "            border-radius: 10px;\n",
        "            border: 2px solid #e0e0e0;\n",
        "            background: #f8f9fa;\n",
        "            margin: 10px 0;\n",
        "        }\n",
        "        .suggestion-btn {\n",
        "            margin: 5px 0 !important;\n",
        "            text-align: left !important;\n",
        "        }\n",
        "    \"\"\"\n",
        ") as demo:\n",
        "\n",
        "    # Header\n",
        "    gr.HTML(\"\"\"\n",
        "        <div class=\"header\">\n",
        "            <h1 style=\"margin: 0; font-size: 2.5em;\">ü§ñ Agente de An√°lise Explorat√≥ria de Dados Aut√¥nomo</h1>\n",
        "            <p style=\"font-size: 1.2em; margin-top: 15px; opacity: 0.95;\">\n",
        "                An√°lise inteligente e automatizada de qualquer dataset CSV usando GPT-4\n",
        "            </p>\n",
        "        </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # Se√ß√£o 1: Carregamento de Dataset\n",
        "    gr.HTML('<div class=\"section-header\">üì• PASSO 1: Carregue seu Dataset e Dispare a An√°lise Aut√¥noma</div>')\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### üì§ Op√ß√£o A: Upload de Arquivo\n",
        "            Fa√ßa upload de qualquer arquivo CSV do seu computador.\n",
        "            \"\"\")\n",
        "            file_upload = gr.File(\n",
        "                label=\"Selecione o arquivo CSV\",\n",
        "                file_types=[\".csv\"],\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "            upload_btn = gr.Button(\"üì• Carregar Arquivo CSV\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### üì¶ Op√ß√£o B: Dataset de Exemplo\n",
        "            Use o dataset de fraude em cart√£o de cr√©dito do Kaggle para testar.\n",
        "            \"\"\")\n",
        "            gr.Markdown(\"**Dataset:** Credit Card Fraud Detection \\n**Tamanho:** ~150MB, 284,807 transa√ß√µes\")\n",
        "            kaggle_btn = gr.Button(\"üì¶ Carregar Dataset do Kaggle\", variant=\"secondary\", size=\"lg\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            upload_status = gr.Markdown(value=\"‚ö†Ô∏è **Aguardando upload de dataset...**\")\n",
        "        with gr.Column():\n",
        "            dataset_status_box = gr.Markdown(value=\"‚ùå **Nenhum dataset carregado**\")\n",
        "\n",
        "    dataset_preview = gr.Dataframe(\n",
        "        label=\"üìä Preview do Dataset (primeiras 5 linhas)\",\n",
        "        wrap=True,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # Exibir a conclus√£o da an√°lise aut√¥noma em destaque\n",
        "    gr.HTML('<div class=\"section-header\" style=\"background: linear-gradient(90deg, #2ecc71 0%, #27ae60 100%);\">üéØ CONCLUS√ÉO DA AN√ÅLISE AUT√îNOMA (Fase 1)</div>')\n",
        "\n",
        "    autonomous_conclusion_display = gr.Markdown(\n",
        "        value=\"A conclus√£o ser√° exibida aqui ap√≥s o carregamento e an√°lise do dataset. üß†\",\n",
        "        label=\"Resumo e Insights do Agente\"\n",
        "    )\n",
        "\n",
        "    # Se√ß√£o 2: Chat com o Agente\n",
        "    gr.HTML('<div class=\"section-header\">üí¨ PASSO 2: Fa√ßa Perguntas Adicionais (o Agente Lembra do Contexto!)</div>')\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"üí¨ Conversa√ß√£o com o Agente\",\n",
        "                height=500,\n",
        "                avatar_images=(\"üë§\", \"ü§ñ\"),\n",
        "                bubble_full_width=False,\n",
        "                show_copy_button=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                msg = gr.Textbox(\n",
        "                    label=\"Sua pergunta (digite livremente ou use as sugest√µes ao lado)\",\n",
        "                    placeholder=\"Ex: Qual foi a correla√ß√£o mais forte que voc√™ encontrou?\",\n",
        "                    lines=3,\n",
        "                    scale=5,\n",
        "                    interactive=False\n",
        "                )\n",
        "                submit_btn = gr.Button(\"Enviar üì§\", variant=\"primary\", scale=1, size=\"lg\", interactive=False)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_chat_btn = gr.Button(\"üóëÔ∏è Limpar Chat\", size=\"sm\")\n",
        "                clear_memory_btn = gr.Button(\"üßπ Resetar Mem√≥ria\", size=\"sm\")\n",
        "\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### üí° Perguntas Sugeridas\")\n",
        "            gr.Markdown(\"*Clique para preencher o campo:*\")\n",
        "\n",
        "            # Criar bot√µes individuais para cada pergunta sugerida\n",
        "            suggestion_1 = gr.Button(\"üìã Repita o resumo da an√°lise\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_2 = gr.Button(\"üîç Me mostre os outliers da coluna 'Amount'\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_3 = gr.Button(\"üìä Distribui√ß√£o das vari√°veis V1 e V2\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_4 = gr.Button(\"üîó Quais as 5 maiores correla√ß√µes positivas?\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_5 = gr.Button(\"‚úçÔ∏è Execute um c√≥digo: print(df.shape)\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_6 = gr.Button(\"üë• Compare 'Time' pela coluna 'Class'\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_7 = gr.Button(\"üìà Quais padr√µes e tend√™ncias voc√™ identificou?\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "            suggestion_8 = gr.Button(\"üéØ Quais s√£o suas conclus√µes finais sobre este dataset?\", size=\"sm\", elem_classes=\"suggestion-btn\")\n",
        "\n",
        "            gr.Markdown(\"---\")\n",
        "            gr.Markdown(\"### üìà Dicas de Uso\")\n",
        "            gr.Markdown(\"\"\"\n",
        "            - üß† O Agente **lembra** de todas as an√°lises aut√¥nomas.\n",
        "            - ‚ùì Fa√ßa perguntas espec√≠ficas (ex: 'coluna X')\n",
        "            - üõ†Ô∏è Use a sugest√£o de **c√≥digo customizado** para an√°lises manuais.\n",
        "            \"\"\")\n",
        "\n",
        "    # Se√ß√£o 3: Informa√ß√µes Adicionais (Accordions)\n",
        "    with gr.Accordion(\"üìä Informa√ß√µes Detalhadas do Dataset\", open=False):\n",
        "        refresh_info_btn = gr.Button(\"üîÑ Atualizar Informa√ß√µes\")\n",
        "        detailed_info = gr.Markdown(value=\"‚ö†Ô∏è Carregue um dataset primeiro\")\n",
        "        refresh_info_btn.click(get_detailed_info, outputs=detailed_info)\n",
        "\n",
        "    with gr.Accordion(\"üìú Hist√≥rico de An√°lises (Mem√≥ria)\", open=False):\n",
        "        refresh_history_btn = gr.Button(\"üîÑ Atualizar Hist√≥rico\")\n",
        "        history_display = gr.Markdown(value=\"‚ö†Ô∏è Nenhuma an√°lise registrada ainda\")\n",
        "        refresh_history_btn.click(update_history, outputs=history_display)\n",
        "\n",
        "    with gr.Accordion(\"üéØ Conclus√µes e Insights Registrados (Mem√≥ria)\", open=False):\n",
        "        refresh_conclusions_btn = gr.Button(\"üîÑ Atualizar Conclus√µes\")\n",
        "        conclusions_display = gr.Markdown(value=\"‚ö†Ô∏è Nenhuma conclus√£o registrada ainda\")\n",
        "        refresh_conclusions_btn.click(update_conclusions, outputs=conclusions_display)\n",
        "\n",
        "    # Footer\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    <div style=\"text-align: center; color: #666; padding: 20px;\">\n",
        "        <p><strong>ü§ñ Agente EDA Aut√¥nomo</strong> | Powered by OpenAI GPT-4 & Gradio</p>\n",
        "        <p style=\"font-size: 0.9em; margin-top: 10px;\">\n",
        "            üí° <strong>Fluxo de uso:</strong> 1Ô∏è‚É£ Carregue um CSV para iniciar a **An√°lise Aut√¥noma** ‚Üí 2Ô∏è‚É£ Revise a Conclus√£o ‚Üí 3Ô∏è‚É£ Fa√ßa perguntas adicionais no Chat!\n",
        "        </p>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "\n",
        "    # Event Handlers\n",
        "\n",
        "    # Upload de arquivo (MODIFICADO para incluir a an√°lise aut√¥noma)\n",
        "    upload_btn.click(\n",
        "        fn=upload_and_update,\n",
        "        inputs=[file_upload],\n",
        "        outputs=[upload_status, dataset_preview, dataset_status_box, msg, submit_btn, chatbot, autonomous_conclusion_display]\n",
        "    )\n",
        "\n",
        "    # Carregar Kaggle (MODIFICADO para incluir a an√°lise aut√¥noma)\n",
        "    kaggle_btn.click(\n",
        "        fn=load_kaggle_and_update,\n",
        "        outputs=[upload_status, dataset_preview, dataset_status_box, msg, submit_btn, chatbot, autonomous_conclusion_display]\n",
        "    )\n",
        "\n",
        "    # Sugest√µes de perguntas - preencher o campo de texto\n",
        "    suggestion_1.click(lambda: \"Repita o resumo da an√°lise que voc√™ fez no modo aut√¥nomo\", outputs=msg)\n",
        "    suggestion_2.click(lambda: \"Me mostre os outliers da coluna 'Amount'\", outputs=msg)\n",
        "    suggestion_3.click(lambda: \"Analise a distribui√ß√£o das vari√°veis V1 e V2\", outputs=msg)\n",
        "    suggestion_4.click(lambda: \"Quais as 5 maiores correla√ß√µes positivas que voc√™ encontrou?\", outputs=msg)\n",
        "    suggestion_5.click(lambda: \"Execute o c√≥digo: print(df.shape)\", outputs=msg)\n",
        "    suggestion_6.click(lambda: \"Compare a coluna 'Time' pela coluna 'Class' (ou outra coluna target)\", outputs=msg)\n",
        "    suggestion_7.click(lambda: \"Quais padr√µes e tend√™ncias voc√™ identificou nos dados?\", outputs=msg)\n",
        "    suggestion_8.click(lambda: \"Quais s√£o suas conclus√µes finais sobre este dataset?\", outputs=msg)\n",
        "\n",
        "    # Chat (MODIFICADO para usar a nova fun√ß√£o de core)\n",
        "    def user_message(message, history):\n",
        "        if not message.strip():\n",
        "            return message, history\n",
        "        return \"\", history + [[message, None]]\n",
        "\n",
        "    def bot_response(history):\n",
        "        if not history or history[-1][1] is not None:\n",
        "            return history\n",
        "\n",
        "        user_msg = history[-1][0]\n",
        "        # Aqui, o process_query chama o run_agent_core em modo chat\n",
        "        updated_history = process_query(user_msg, history[:-1])\n",
        "        return updated_history\n",
        "\n",
        "    msg.submit(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot_response, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "    submit_btn.click(user_message, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot_response, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "    # Limpar chat\n",
        "    clear_chat_btn.click(clear_chat_history, outputs=chatbot)\n",
        "\n",
        "    # Resetar mem√≥ria\n",
        "    def reset_and_notify():\n",
        "        memory.reset()\n",
        "        # Ap√≥s o reset, precisamos garantir que o chat reflita o estado\n",
        "        return [], \"‚úÖ Mem√≥ria resetada! O dataset e as conclus√µes anteriores foram limpos. O chat est√° pronto para novas an√°lises.\"\n",
        "\n",
        "    clear_memory_btn.click(\n",
        "        fn=reset_and_notify,\n",
        "        outputs=[chatbot, autonomous_conclusion_display]\n",
        "    )\n",
        "\n",
        "# Iniciar a interface\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üöÄ INICIANDO INTERFACE GRADIO...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Lan√ßar aplica√ß√£o\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=False,\n",
        "    show_error=True\n",
        ")"
      ],
      "metadata": {
        "id": "I7_eCfRUnzdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "e5459a2c-9003-413f-ac01-81c828f7898e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üöÄ INICIANDO INTERFACE GRADIO...\n",
            "================================================================================\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f66201faf0bb814091.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f66201faf0bb814091.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}